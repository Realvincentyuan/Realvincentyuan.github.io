<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:media="http://search.yahoo.com/mrss/"><channel><title><![CDATA[Spacecraft]]></title><description><![CDATA[Thoughts, stories and ideas.]]></description><link>http://localhost:2368/</link><image><url>http://localhost:2368/favicon.png</url><title>Spacecraft</title><link>http://localhost:2368/</link></image><generator>Ghost 5.49</generator><lastBuildDate>Mon, 12 Jun 2023 01:59:54 GMT</lastBuildDate><atom:link href="http://localhost:2368/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[Permutation Importance for Feature Selection]]></title><description><![CDATA[<h2 id="1-introduction">1 Introduction</h2><p>In previous articles, some common feature selection techniques have been introduced. In this article, we will continue to focus on this topic and explain a new method for assessing feature importance: Permutation Importance. </p><h2 id="2-algorithm-deconstruction">2 Algorithm Deconstruction</h2><p>Permutation Importance is suitable for tabular data, and its assessment of feature</p>]]></description><link>http://localhost:2368/permutation-importance-for-feature-selection/</link><guid isPermaLink="false">64863dbc4543c30001eef972</guid><category><![CDATA[Tech]]></category><category><![CDATA[AI]]></category><category><![CDATA[Python]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sat, 22 Jan 2022 06:00:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1591453089816-0fbb971b454c?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDh8fG1hY2hpbmUlMjBsZWFybmluZ3xlbnwwfHx8fDE2ODY1MTkyMzN8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<h2 id="1-introduction">1 Introduction</h2><img src="https://images.unsplash.com/photo-1591453089816-0fbb971b454c?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDh8fG1hY2hpbmUlMjBsZWFybmluZ3xlbnwwfHx8fDE2ODY1MTkyMzN8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Permutation Importance for Feature Selection"><p>In previous articles, some common feature selection techniques have been introduced. In this article, we will continue to focus on this topic and explain a new method for assessing feature importance: Permutation Importance. </p><h2 id="2-algorithm-deconstruction">2 Algorithm Deconstruction</h2><p>Permutation Importance is suitable for tabular data, and its assessment of feature importance depends on the extent to which the model performance score decreases when the feature is randomly rearranged. Its mathematical expression can be represented as:</p><figure class="kg-card kg-image-card"><img src="http://localhost:2368/content/images/2023/06/image-19.png" class="kg-image" alt="Permutation Importance for Feature Selection" loading="lazy" width="1522" height="732" srcset="http://localhost:2368/content/images/size/w600/2023/06/image-19.png 600w, http://localhost:2368/content/images/size/w1000/2023/06/image-19.png 1000w, http://localhost:2368/content/images/2023/06/image-19.png 1522w" sizes="(min-width: 720px) 720px"></figure><h2 id="3-example-code">3 Example Code</h2><pre><code class="language-python">from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Ridge
from sklearn.inspection import permutation_importance
diabetes = load_diabetes()
X_train, X_val, y_train, y_val = train_test_split(
    diabetes.data, diabetes.target, random_state=0)

model = Ridge(alpha=1e-2).fit(X_train, y_train)
model.score(X_val, y_val)


scoring = [&apos;r2&apos;, &apos;neg_mean_absolute_percentage_error&apos;, &apos;neg_mean_squared_error&apos;]
# The scoring parameter can include multiple calculation indicators at the same time. This is more efficient than using permutation_importance repeatedly, because the predicted value can be used to calculate different indicators.
r_multi = permutation_importance(model, X_val, y_val, n_repeats=30, random_state=0, scoring=scoring)

for metric in r_multi:
    print(f&quot;{metric}&quot;)
    r = r_multi[metric]
    for i in r.importances_mean.argsort()[::-1]:
        if r.importances_mean[i] - 2 * r.importances_std[i] &gt; 0:
            print(f&quot;    {diabetes.feature_names[i]:&lt;8}&quot;
                  f&quot;{r.importances_mean[i]:.3f}&quot;
                  f&quot; +/- {r.importances_std[i]:.3f}&quot;)

</code></pre><p>The output is:</p><pre><code class="language-python">r2
  s5      0.204 +/- 0.050
  bmi     0.176 +/- 0.048
  bp      0.088 +/- 0.033
  sex     0.056 +/- 0.023
neg_mean_absolute_percentage_error
  s5      0.081 +/- 0.020
  bmi     0.064 +/- 0.015
  bp      0.029 +/- 0.010
neg_mean_squared_error
  s5      1013.903 +/- 246.460
  bmi     872.694 +/- 240.296
  bp      438.681 +/- 163.025
  sex     277.382 +/- 115.126
</code></pre><h2 id="4-conclusion">4 Conclusion</h2><p>Compared with tree models, feature importance is usually judged based on the decrease in impurity, which is usually based on the <code>training set</code>. When the model is overfitting, the importance of features is misleading. In this case, seemingly important features may not have satisfactory predictive power for new data encountered by the model online.</p><p>At the same time, feature importance based on reduction in impurity is easily affected by high-cardinality features, so numerical variables often rank higher. In contrast, Permutation Importance has no bias towards model features and is not limited to specific model types, so it has a wide range of applications. Please note that if the features have strong multicollinearity, it is recommended to take only one important feature. The method can be viewed in this <a href="https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance_multicollinear.html?ref=localhost#sphx-glr-auto-examples-inspection-plot-permutation-importance-multicollinear-py">example</a>.</p><p>At the same time, <code>Scikit Learn</code> also provides an intuitive <a href="https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance.html?ref=localhost#sphx-glr-auto-examples-inspection-plot-permutation-importance-py">example</a> to demonstrate the difference between feature importance based on impurity reduction and Permutation Importance.</p><p>Hope this sharing is helpful to you, and welcome to leave comments for discussion!</p>]]></content:encoded></item><item><title><![CDATA[Automatically Build and Push Docker Image with GitHub Action]]></title><description><![CDATA[<h2 id="1-introduction">1 Introduction</h2><p>In this article, we will introduce how to use GitHub Action to automatically push Docker images to a registry, greatly simplifying the tedious process of building and pushing images! We have introduced many cool features of GitHub before. To facilitate the understanding of the content of this article,</p>]]></description><link>http://localhost:2368/automatically-build-and-push-docker-image-with-github-action/</link><guid isPermaLink="false">648639d44543c30001eef942</guid><category><![CDATA[Tech]]></category><category><![CDATA[GitHub]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sat, 20 Nov 2021 06:00:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1591608516485-a1a53df39498?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDZ8fGdpdGh1YnxlbnwwfHx8fDE2ODY1MTI2NjJ8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<h2 id="1-introduction">1 Introduction</h2><img src="https://images.unsplash.com/photo-1591608516485-a1a53df39498?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDZ8fGdpdGh1YnxlbnwwfHx8fDE2ODY1MTI2NjJ8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Automatically Build and Push Docker Image with GitHub Action"><p>In this article, we will introduce how to use GitHub Action to automatically push Docker images to a registry, greatly simplifying the tedious process of building and pushing images! We have introduced many cool features of GitHub before. To facilitate the understanding of the content of this article, we recommend reviewing the basic GitHub operation knowledge in the previous article, especially GitHub Action:</p><ul><li><a href="http://localhost:2368/how-to-use-github-without-writing-a-single-line-of-code">Teaching You to Use GitHub with One Line of Code</a></li><li><a href="http://localhost:2368/a-list-of-common-git-commands">Git Common Commands Overview</a></li><li><a href="http://localhost:2368/creating-a-beautiful-online-resume-using-github">Create a Beautiful Online Resume with GitHub</a></li><li><a href="http://localhost:2368/github-action-overview">Overview of GitHub Action</a></li></ul><h2 id="2-configure-the-image-registry">2 Configure the Image Registry</h2><p>Here we take Aliyun&apos;s image registry as an example for demonstration. The principles of other image registries are similar and can be applied by analogy. First, log in to the <a href="https://cr.console.aliyun.com/cn-shanghai/instance/repositories?ref=localhost">Aliyun image registry</a>, and perform the following operations:</p><ul><li>Create a namespace as a collection of image repositories, named after the company or organization. We use <code>bullettech_services</code>.</li><li>Create an image repository as a collection of images that can store different versions of images in the repository.</li></ul><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/registry.png" class="kg-image" alt="Automatically Build and Push Docker Image with GitHub Action" loading="lazy"><figcaption>Image Registry</figcaption></figure><h2 id="3-configure-the-github-action">3 Configure the GitHub Action</h2><h3 id="31-configure-the-password">3.1 Configure the Password</h3><p>Set a password in the GitHub repository for logging in to the image registry. You can find the password in the repository settings and then store the login name and password of the image registry service.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/secrets.png" class="kg-image" alt="Automatically Build and Push Docker Image with GitHub Action" loading="lazy"><figcaption>Store the login name and password of the image registry service</figcaption></figure><h3 id="32-create-the-workflow">3.2 Create the Workflow</h3><p>First, create a workflow in the <code>.github/workflows</code> directory, such as <code>ci.yml</code>, and understand the commands based on the comments, and modify them according to the project situation.</p><pre><code class="language-yml">name: actions

on: [push, pull_request] # Trigger Event

jobs:
  bt-product-release:
    if: ${{ github.ref == &apos;refs/heads/main&apos; }}  # Check if the main branch is updated
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2 # pull the code to the running server
    - name: Login to Aliyun Container Registry (ACR)
      uses: aliyun/acr-login@v1 # Use the Aliyun Image Service Action
      with:
        login-server: registry.cn-shanghai.aliyuncs.com # Be sure to correctly fill in the login address of the image registry service
        region-id: cn-shanghai
        username: &quot;${{ secrets.REGISTRY_USERNAME }}&quot; # Reference the username of the image registry service set in GitHub repo
        password: &quot;${{ secrets.REGISTRY_PASSWORD }}&quot; # Reference the password of the image registry service set in GitHub repo
    - name: Build and Push Docker Image
      env:
        IMAGE_TAG: ${{ github.sha }} # Used to mark the container version number
      run: |
        docker build -t registry.cn-shanghai.aliyuncs.com/bullettech_services/app:$IMAGE_TAG .
        docker push registry.cn-shanghai.aliyuncs.com/bullettech_services/app:$IMAGE_TAG
</code></pre><p>This way, every time the main branch is updated, GitHub will build the image based on the updated code, and push the image to the designated image repository (pay attention to the version):</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/images.png" class="kg-image" alt="Automatically Build and Push Docker Image with GitHub Action" loading="lazy"><figcaption>Image</figcaption></figure><h2 id="4-conclusion">4 Conclusion</h2><p>This efficient workflow saves a lot of time and avoids many errors that are prone to occur during manual operations. GitHub Action is so awesome!</p><p>I hope this sharing will help you, and welcome to leave a message in the comments to discuss!</p>]]></content:encoded></item><item><title><![CDATA[GitHub Action Overview]]></title><description><![CDATA[<h2 id="1-introduction">1 Introduction</h2><p>We have introduced many cool features of GitHub before. To better understand the content of this article, it is recommended to review the basic GitHub operation knowledge in the previous articles:</p><ul><li><a href="http://localhost:2368/how-to-use-github-without-writing-a-single-line-of-code">Teach You How to Use GitHub without Writing Any Code</a></li><li><a href="http://localhost:2368/a-list-of-common-git-commands">Git Commonly Used Commands</a></li><li><a href="http://localhost:2368/creating-a-beautiful-online-resume-using-github">Create a Beautiful</a></li></ul>]]></description><link>http://localhost:2368/github-action-overview/</link><guid isPermaLink="false">648639194543c30001eef929</guid><category><![CDATA[Tech]]></category><category><![CDATA[GitHub]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sat, 13 Nov 2021 06:00:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1591608516485-a1a53df39498?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDZ8fGdpdGh1YnxlbnwwfHx8fDE2ODY1MTI2NjJ8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<h2 id="1-introduction">1 Introduction</h2><img src="https://images.unsplash.com/photo-1591608516485-a1a53df39498?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDZ8fGdpdGh1YnxlbnwwfHx8fDE2ODY1MTI2NjJ8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="GitHub Action Overview"><p>We have introduced many cool features of GitHub before. To better understand the content of this article, it is recommended to review the basic GitHub operation knowledge in the previous articles:</p><ul><li><a href="http://localhost:2368/how-to-use-github-without-writing-a-single-line-of-code">Teach You How to Use GitHub without Writing Any Code</a></li><li><a href="http://localhost:2368/a-list-of-common-git-commands">Git Commonly Used Commands</a></li><li><a href="http://localhost:2368/creating-a-beautiful-online-resume-using-github">Create a Beautiful Online Resume Using GitHub</a></li></ul><p>In this article, we will introduce how to use GitHub Actions to simplify repeated mechanical tasks and greatly improve efficiency and save time.</p><h2 id="2-github-action-overview">2 GitHub Action Overview</h2><p>GitHub Action can automatically execute custom scripts to complete preset work. Users need to set the triggering conditions (events) and the commands to be executed when the conditions are met. GitHub can automatically complete the preset operations, for example, when a update is merged to the master/main branch, automatically execute the test script to check for errors. The following figure shows the components when GitHub Action is executed:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/overview-actions-design.png" class="kg-image" alt="GitHub Action Overview" loading="lazy"><figcaption>GitHub Action components, source: GitHub</figcaption></figure><p>When an event occurs, GitHub automatically triggers the workflow. Then the program executes step by step.</p><h2 id="3-create-action">3 Create Action</h2><p>GitHub Action uses <a href="https://yaml.org/?ref=localhost">YAML</a> to define the triggered events, work, and steps. The workflow file needs to be stored in a specific location in the code repository: <code>.github/workflows</code>.</p><p>Take the continuous integration workflow of the <a href="https://github.com/BulletTech/BulletTech/blob/main/.github/workflows/ci.yml?ref=localhost">BulletTech blog</a> as an example:</p><pre><code class="language-yml">name: ci
on:
  push:
    branches:
      - main
jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-python@v2
        with:
          python-version: 3.x
      - run: python ./docs/Scripts/Update_reading_time.py
      - run: pip install mkdocs-material
      - run: pip install mkdocs-redirects
      - run: pip install mkdocs-minify-plugin
      - run: pip install mkdocs-macros-plugin
      - run: pip install mkdocs-git-revision-date-localized-plugin
      - run: pip install --upgrade mkdocs-material
      - run: pip install --upgrade mkdocs-redirects
      - run: pip install --upgrade mkdocs-minify-plugin
      - run: pip install --upgrade mkdocs-macros-plugin
      - run: pip install --upgrade mkdocs-git-revision-date-localized-plugin   
      - run: git pull
      - run: mkdocs gh-deploy --force
</code></pre><p>Key points are as follows:</p><ul><li><code>name</code> defines the name of the workflow, in this case, continuous integration (CI).</li><li><code>on</code> is the event that triggers the workflow. Here, it is defined that the command needs to be executed when a push is updated to the main branch.</li><li><code>jobs</code> defines the work tasks. <code>deploy</code> is the name of the work. It runs a series of steps on GitHub&apos;s Ubuntu Linux virtual machine.</li><li><code>uses</code> is followed by an action in GitHub Action Marketplace. Here, actions are used to check out the repository and download the code to the server that runs the code, and configure the Python runtime environment.</li><li><code>run</code> is followed by the command to be executed. Here, some Python packages required by the blog are installed and the deployment command is run.</li></ul><h2 id="4-check-action-status">4 Check Action Status</h2><p>In the Actions tab of the GitHub repository, you can see the running status of the action:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/Action_Status.png" class="kg-image" alt="GitHub Action Overview" loading="lazy"><figcaption>GitHub Action status</figcaption></figure><p>You can see the <code>ci</code> workflow used by BulletTech, and click on <code>runs</code> to view the running status of each step of the action.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/Action_steps.png" class="kg-image" alt="GitHub Action Overview" loading="lazy"><figcaption>Action running status</figcaption></figure><h2 id="5-conclusion">5 Conclusion</h2><p>Using GitHub Action automates many repetitive and mechanical labor tasks, saving time that can be used for more meaningful things. For more information, please refer to the following reference materials to customize your own workflow.</p><p>I hope this sharing can help you. Feel free to leave a comment in the comment section for discussion!</p>]]></content:encoded></item><item><title><![CDATA[Creating a Beautiful Online Resume using GitHub]]></title><description><![CDATA[<h2 id="1-introduction">1 Introduction</h2><p>We have previously introduced many cool features of GitHub. To better understand the content of this article, it is recommended to read previous articles to review the basic knowledge of GitHub operations:</p><ul><li><a href="http://localhost:2368/how-to-use-github-without-writing-a-single-line-of-code">Teaching You to Use GitHub without Writing a Single Line of Code</a></li><li><a href="http://localhost:2368/a-list-of-common-git-commands">Git Commonly Used Commands</a></li></ul>]]></description><link>http://localhost:2368/creating-a-beautiful-online-resume-using-github/</link><guid isPermaLink="false">648638834543c30001eef90f</guid><category><![CDATA[Tech]]></category><category><![CDATA[GitHub]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Wed, 03 Nov 2021 05:00:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1591608516485-a1a53df39498?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDZ8fGdpdGh1YnxlbnwwfHx8fDE2ODY1MTI2NjJ8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<h2 id="1-introduction">1 Introduction</h2><img src="https://images.unsplash.com/photo-1591608516485-a1a53df39498?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDZ8fGdpdGh1YnxlbnwwfHx8fDE2ODY1MTI2NjJ8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Creating a Beautiful Online Resume using GitHub"><p>We have previously introduced many cool features of GitHub. To better understand the content of this article, it is recommended to read previous articles to review the basic knowledge of GitHub operations:</p><ul><li><a href="http://localhost:2368/how-to-use-github-without-writing-a-single-line-of-code">Teaching You to Use GitHub without Writing a Single Line of Code</a></li><li><a href="http://localhost:2368/a-list-of-common-git-commands">Git Commonly Used Commands</a></li></ul><p>In this article, we will introduce how to use GitHub to create an online resume and build a website that everyone can access to showcase oneself.</p><h2 id="2-creating-an-online-resume">2 Creating an Online Resume</h2><h3 id="21-downloading-example-code">2.1 Downloading Example Code</h3><p>This example uses a Bootstrap template, please go to BulletTech&apos;s official GitHub account and find the [Resume repository](<a href="https://github.com/BulletTech2021/Resume?ref=localhost">https://github.com/BulletTech2021/Resume</a> &apos;BulletTech&apos;s Resume Example Code&apos;) to download the example code.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/Resume%E4%BB%93%E5%BA%93.png" class="kg-image" alt="Creating a Beautiful Online Resume using GitHub" loading="lazy"><figcaption>BulletTech&apos;s Resume Repository</figcaption></figure><p>The code that needs to be modified exists in <code>/home/index.html</code>:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/home%E6%BA%90%E4%BB%A3%E7%A0%81.png" class="kg-image" alt="Creating a Beautiful Online Resume using GitHub" loading="lazy"><figcaption>Homepage Source Code</figcaption></figure><h3 id="22-modifying-example-code">2.2 Modifying Example Code</h3><p>After downloading the source code, double-click <code>index.html</code> to preview it in real-time. Use <code>ctrl/command+F</code> to find and modify the corresponding elements in comparison with the webpage content. The webpage will display the latest content after refreshing. You can also modify the CSS (<code>home/css/styles.css</code>) and other components for deep customization.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/Resume.png" class="kg-image" alt="Creating a Beautiful Online Resume using GitHub" loading="lazy"><figcaption>Previewing the Resume on Local Machine</figcaption></figure><h3 id="23-publishing-the-resume">2.3 Publishing the Resume</h3><p>Create your own GitHub repository and submit the modified code to your repository. Check the website to ensure that the complete code is uploaded. Then activate the GitHub Pages feature. By default, select root under the master/main branch. Click on the corresponding URL to access your own resume.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/GitHub_Pages.png" class="kg-image" alt="Creating a Beautiful Online Resume using GitHub" loading="lazy"><figcaption>Setting Up GitHub Pages</figcaption></figure><h2 id="3-conclusion">3 Conclusion</h2><p>We have added another little trick to the use of GitHub. You are welcome to use the above steps to create your own online resume. BulletTech&apos;s <a href="https://bullettech2021.github.io/Resume/home/?ref=localhost">example resume</a> can be accessed at <code>https://bullettech2021.github.io/Resume/home/</code>.</p><p>Hope this sharing is helpful to you. Welcome to leave a message in the comments area for discussion!</p>]]></content:encoded></item><item><title><![CDATA[PicGo Image Hosting Tool, Just Right!]]></title><description><![CDATA[<h2 id="1-introduction">1 Introduction</h2><p>Pictures are indispensable in the workflow of self-media. A good image hosting can conveniently manage and reference pictures. In the article &quot;How to write a beautiful WeChat article in the quickest way possible,&quot; we introduced how to build an effective workflow. However, for some reasons, the</p>]]></description><link>http://localhost:2368/picgo-image-hosting-just-right/</link><guid isPermaLink="false">648637a84543c30001eef901</guid><category><![CDATA[Tech]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sat, 23 Oct 2021 05:00:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1508004680771-708b02aabdc0?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDExfHxwaWN0dXJlfGVufDB8fHx8MTY4NjUxNzY4MHww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<h2 id="1-introduction">1 Introduction</h2><img src="https://images.unsplash.com/photo-1508004680771-708b02aabdc0?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDExfHxwaWN0dXJlfGVufDB8fHx8MTY4NjUxNzY4MHww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="PicGo Image Hosting Tool, Just Right!"><p>Pictures are indispensable in the workflow of self-media. A good image hosting can conveniently manage and reference pictures. In the article &quot;How to write a beautiful WeChat article in the quickest way possible,&quot; we introduced how to build an effective workflow. However, for some reasons, the GitHub image hosting in mdnice is no longer available. Therefore, we introduce a new practical image hosting tool - PicGo in this article.</p><h2 id="2-install-picgo">2 Install PicGo</h2><p>PicGo supports Windows, macOS, and Linux platforms, and installation files for each platform can be downloaded from its <a href="https://github.com/Molunerfinn/PicGo/releases?ref=localhost">GitHub official website</a>.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/%E4%B8%8B%E8%BD%BDPicGo.png" class="kg-image" alt="PicGo Image Hosting Tool, Just Right!" loading="lazy"><figcaption>Download PicGo</figcaption></figure><p>After installation, you can see the main interface of PicGo:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/PicGo%E4%B8%BB%E7%95%8C%E9%9D%A2.png" class="kg-image" alt="PicGo Image Hosting Tool, Just Right!" loading="lazy"><figcaption>PicGo main interface</figcaption></figure><p>Different functions can be switched on the left-hand side. As shown in the figure, the upload area is the same as all the uploaded pictures in the album. The configuration area will be introduced in detail below.</p><h2 id="3-configure-github-image-hosting">3 Configure GitHub Image Hosting</h2><p>PicGo supports multiple image hosting, such as SMMS, Qiniu Image Hosting, Tencent Cloud COS, UpYun Image Hosting, GitHub Image Hosting, Alibaba Cloud OSS, Imgur Image Hosting, etc. This tutorial uses the free GitHub Image Hosting as an example to describe the configuration process.</p><p>Firstly, a GitHub account is necessary, and basic GitHub operations need to be familiar with. You can refer to the article &#x201C;Teaches You to Use GitHub Without Writing a Line of Code&#x201D; for learning. After registering for GitHub, generate Personal Access Tokens in <code>Personal Access Tokens</code> -&gt; <code>Developer Settings</code>. Only check the box for the repo to generate the token. As it is only displayed once, please be sure to save the token for later use.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/Personal_access_tokens.png" class="kg-image" alt="PicGo Image Hosting Tool, Just Right!" loading="lazy"><figcaption>Personal access tokens</figcaption></figure><p>Then configure parameters as shown below:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/%E9%85%8D%E7%BD%AEPicGo.png" class="kg-image" alt="PicGo Image Hosting Tool, Just Right!" loading="lazy"><figcaption>Configure PicGo</figcaption></figure><p>Generally, selecting the main branch is sufficient, but please note that it is best to specify the storage path to a folder rather than all piled up in the root directory of the branch. At the same time, setting a custom domain name can speed up the loading of images. BulletTech uses <code>https://cdn.jsdelivr.net/gh/BulletTech2021/Pics</code>.</p><p>After the configuration is complete, drag the picture to the upload area, and you can see that the picture will be uploaded to GitHub automatically. At the same time, the image reference link (<code>https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/Pics_in_github.png</code>) is automatically copied to the clipboard. This link can be used on various platforms to display the image.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/Pics_in_github.png" class="kg-image" alt="PicGo Image Hosting Tool, Just Right!" loading="lazy"><figcaption>The image has been uploaded to GitHub</figcaption></figure><h2 id="4-conclusion">4 Conclusion</h2><p>PicGo is open-source and free. It has stable and reliable software quality and the developer is still updating the software. You can also conduct secondary development based on its foundation. This practical tool can significantly improve the efficiency of self-media workers!</p><p>I hope this sharing can be helpful to you. Welcome to leave a message in the comment section for discussion.</p>]]></content:encoded></item><item><title><![CDATA[SnowFlake Permission Overview]]></title><description><![CDATA[<h2 id="1-introduction">1 Introduction</h2><p>Properly managing permissions for objects (such as databases and tables) in a database is very important but often overlooked. When it comes to permission issues and problems, people will regret not taking permission management seriously. Therefore, this article will take the very popular SnowFlake data warehouse as an</p>]]></description><link>http://localhost:2368/snowflake-permission-overview/</link><guid isPermaLink="false">648636e94543c30001eef8ef</guid><category><![CDATA[Tech]]></category><category><![CDATA[Analytics]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Mon, 11 Oct 2021 05:00:00 GMT</pubDate><media:content url="http://localhost:2368/content/images/2023/06/Screenshot-2023-06-11-at-3.45.17-PM.png" medium="image"/><content:encoded><![CDATA[<h2 id="1-introduction">1 Introduction</h2><img src="http://localhost:2368/content/images/2023/06/Screenshot-2023-06-11-at-3.45.17-PM.png" alt="SnowFlake Permission Overview"><p>Properly managing permissions for objects (such as databases and tables) in a database is very important but often overlooked. When it comes to permission issues and problems, people will regret not taking permission management seriously. Therefore, this article will take the very popular SnowFlake data warehouse as an example, succinctly explaining important concepts and commonly used commands for permission management. It is recommended to like and bookmark for later review and use!</p><h2 id="2-snowflake-permission-control-framework">2 SnowFlake Permission Control Framework</h2><p>SnowFlake has two permission control models:</p><ul><li>Discretionary Access Control (DAC): Each object has an owner who can grant different permissions to others.</li><li>Role-based Access Control (RBAC): Access permissions are controlled by roles, which can be assigned to different users.</li></ul><p>In SnowFlake, there are some important concepts that help understand permission control:</p><ul><li>Securable object: An entity that can be granted specific permissions. If you do not have permission, access to the object will be denied.</li><li>Role: An entity that can receive permissions, which can be assigned to users or other roles to form different role hierarchies.</li><li>Privilege: The level of access control for objects. By setting different privileges, the granularity of access control can be controlled.</li><li>User: An identity that can be recognized by SnowFlake and can be a person or a program.</li></ul><p>In SnowFlake, the permission control of securable objects is shown in the figure below. Access to securable objects can be granted by assigning permissions to roles, which means that permissions are assigned to other roles or objects. In addition, each securable object has an owner who can grant permissions to other roles.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/access-control-relationships.png" class="kg-image" alt="SnowFlake Permission Overview" loading="lazy"><figcaption>SnowFlake Permission Control Diagram</figcaption></figure><h2 id="3-common-commands">3 Common Commands</h2><p>After a basic understanding of how SnowFlake manages permissions, using commands to operate and view permissions will be more convenient.</p><h3 id="31-granting-permissions">3.1 Granting Permissions</h3><pre><code class="language-sql">GRANT {  { globalPrivileges         | ALL [ PRIVILEGES ] } ON ACCOUNT
       | { accountObjectPrivileges  | ALL [ PRIVILEGES ] } ON { USER | RESOURCE MONITOR | WAREHOUSE | DATABASE | INTEGRATION } &lt;object_name&gt;
       | { schemaPrivileges         | ALL [ PRIVILEGES ] } ON { SCHEMA &lt;schema_name&gt; | ALL SCHEMAS IN DATABASE &lt;db_name&gt; }
       | { schemaPrivileges         | ALL [ PRIVILEGES ] } ON { FUTURE SCHEMAS IN DATABASE &lt;db_name&gt; }
       | { schemaObjectPrivileges   | ALL [ PRIVILEGES ] } ON { &lt;object_type&gt; &lt;object_name&gt; | ALL &lt;object_type_plural&gt; IN { DATABASE &lt;db_name&gt; | SCHEMA &lt;schema_name&gt; } }
       | { schemaObjectPrivileges   | ALL [ PRIVILEGES ] } ON FUTURE &lt;object_type_plural&gt; IN { DATABASE &lt;db_name&gt; | SCHEMA &lt;schema_name&gt; }
      }
  TO [ ROLE ] &lt;role_name&gt; [ WITH GRANT OPTION ]
</code></pre><p>Where:</p><pre><code class="language-sql">globalPrivileges ::=
  { { CREATE { ROLE | USER | WAREHOUSE | DATABASE | INTEGRATION } } | APPLY MASKING POLICY | APPLY ROW ACCESS POLICY | APPLY TAG | EXECUTE TASK | MANAGE GRANTS | MONITOR { EXECUTION | USAGE }  } [ , ... ]

accountObjectPrivileges ::=
-- For USER
  { MONITOR } [ , ... ]
-- For RESOURCE MONITOR
  { MODIFY | MONITOR } [ , ... ]
-- For WAREHOUSE
  { MODIFY | MONITOR | USAGE | OPERATE } [ , ... ]
-- For DATABASE
  { MODIFY | MONITOR | USAGE | CREATE SCHEMA | IMPORTED PRIVILEGES } [ , ... ]
-- For INTEGRATION
  { USAGE | USE_ANY_ROLE } [ , ... ]

schemaPrivileges ::=
    { MODIFY | MONITOR | USAGE | CREATE { TABLE | EXTERNAL TABLE | VIEW | MATERIALIZED VIEW | MASKING POLICY | ROW ACCESS POLICY | TAG | SEQUENCE | FUNCTION | PROCEDURE | FILE FORMAT | STAGE | PIPE | STREAM | TASK } } [ , ... ]

schemaObjectPrivileges ::=
    -- For TABLE
      { SELECT | INSERT | UPDATE | DELETE | TRUNCATE | REFERENCES } [ , ... ]
    -- For VIEW
      { SELECT | REFERENCES } [ , ... ]
    -- For MATERIALIZED VIEW
        SELECT
    -- For SEQUENCE, FUNCTION (UDF or external function), PROCEDURE, or FILE FORMAT
        USAGE
    -- For internal STAGE
        READ [ , WRITE ]
    -- For external STAGE
        USAGE
    -- For PIPE
       { MONITOR | OPERATE } [ , ... ]
    -- For STREAM
        SELECT
    -- For TASK
       { MONITOR | OPERATE } [ , ... ]
    -- For MASKING POLICY
        APPLY
    -- For ROW ACCESS POLICY
        APPLY
    -- For TAG
        APPLY
</code></pre><p>The full list of all permissions can be found in SnowFlake&apos;s <a href="https://docs.snowflake.com/en/user-guide/security-access-control-privileges.html?ref=localhost">API documentation</a>.</p><p>The required parameters are <code>object_name</code>, <code>object_type</code>, <code>object_type_plural</code>, and <code>role_name</code>, which are self-explanatory. Optional parameters include:</p><ul><li><code>ON FUTURE</code>: Specifies that the permission is granted to tables or views in a new database or schema, not existing objects.</li><li><code>WITH GRANT OPTION</code>: Specifies whether the recipient role is allowed to grant permissions to other roles.</li></ul><p>Examples are as follows:</p><pre><code class="language-sql"># Specify that the role can continue to grant permissions with grant option
grant operate on warehouse report_wh to role analyst with grant option;

# Grant select permission on all tables in schema mydb.myschema to role analyst
grant select on all tables in schema mydb.myschema to role analyst;
</code></pre><h3 id="32-viewing-permissions">3.2 Viewing Permissions</h3><p>You can view object permissions using the <code>SHOW GRANTS</code> command, as shown below:</p><pre><code class="language-sql">SHOW GRANTS ON ACCOUNT

SHOW GRANTS ON &lt;object_type&gt; &lt;object_name&gt;

SHOW GRANTS TO { ROLE &lt;role_name&gt; | USER &lt;user_name&gt; | SHARE &lt;share_name&gt; }

SHOW GRANTS OF ROLE &lt;role_name&gt;

SHOW GRANTS OF SHARE &lt;share_name&gt;

SHOW FUTURE GRANTS IN SCHEMA { &lt;schema_name&gt; }

SHOW FUTURE GRANTS IN DATABASE { &lt;database_name&gt; }
</code></pre><h3 id="33-revoking-permissions">3.3 Revoking Permissions</h3><p>The <code>REVOKE</code> keyword is used to revoke permissions:</p><pre><code>REVOKE [ GRANT OPTION FOR ]
    {
       { globalPrivileges         | ALL [ PRIVILEGES ] } ON ACCOUNT
     | { accountObjectPrivileges  | ALL [ PRIVILEGES ] } ON { RESOURCE MONITOR | WAREHOUSE | DATABASE | INTEGRATION } &lt;object_name&gt;
     | { schemaPrivileges         | ALL [ PRIVILEGES ] } ON { SCHEMA &lt;schema_name&gt; | ALL SCHEMAS IN DATABASE &lt;db_name&gt; }
     | { schemaPrivileges         | ALL [ PRIVILEGES ] } ON { FUTURE SCHEMAS IN DATABASE &lt;db_name&gt; }
     | { schemaObjectPrivileges   | ALL [ PRIVILEGES ] } ON { &lt;object_type&gt; &lt;object_name&gt; | ALL &lt;object_type_plural&gt; IN SCHEMA &lt;schema_name&gt; }
     | { schemaObjectPrivileges   | ALL [ PRIVILEGES ] } ON FUTURE &lt;object_type_plural&gt; IN { DATABASE &lt;db_name&gt; | SCHEMA &lt;schema_name&gt; }
    }
  FROM [ ROLE ] &lt;role_name&gt; [ RESTRICT | CASCADE ]
</code></pre><p>The mandatory parameters are the same as the <code>GRANT</code> command, and the optional parameters include:</p><ul><li><code>GRANT OPTION FOR</code>: If specified, the recipient will not be allowed to grant the permissions to other roles.</li><li><code>ON FUTURE</code>: If specified, only the permissions on new objects will be revoked, while the permissions on existing objects will remain valid.</li><li><code>RESTRICT | CASCADE</code>: Depending on whether the permissions are granted to other roles, if <code>CASCADE</code> is used, all dependent grants will be revoked. However, when <code>RESTRICT</code> is used, the <code>REVOKE</code> command will not be executed if the permissions are granted to other roles.</li></ul><h2 id="4-summary">4 Summary</h2><p>The above content summarizes the important aspects of managing permissions in Snowflake. It is recommended to create different roles correctly and assign the appropriate permissions to them based on actual work requirements. If necessary, further refer to Snowflake&apos;s <a href="https://docs.snowflake.com/en/user-guide/security-access-control-overview.html?ref=localhost">official documentation</a>.</p><p>I hope this sharing has been helpful to you. Feel free to leave a comment in the discussion area!</p>]]></content:encoded></item><item><title><![CDATA[Installing TensorFlow on Apple Silicon Macs]]></title><description><![CDATA[<h2 id="1-introduction">1 Introduction</h2><p>Although Apple Silicon Macs have shown outstanding performance, compatibility issues still cannot be ignored for ordinary users. Installing TensorFlow on Apple Silicon is not as simple as typing <code>pip install tensorflow</code> on Intel Macs. However, numerous developers and Apple itself are working tirelessly to optimize Apple Silicon Macs.</p>]]></description><link>http://localhost:2368/installing-tensorflow-on-apple-silicon-macs/</link><guid isPermaLink="false">648636104543c30001eef8de</guid><category><![CDATA[Tech]]></category><category><![CDATA[AI]]></category><category><![CDATA[Python]]></category><category><![CDATA[Apple]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sun, 10 Oct 2021 05:00:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1659135890084-930731031f40?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDEyfHxtMSUyMHByb3xlbnwwfHx8fDE2ODY1MTczNTR8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<h2 id="1-introduction">1 Introduction</h2><img src="https://images.unsplash.com/photo-1659135890084-930731031f40?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDEyfHxtMSUyMHByb3xlbnwwfHx8fDE2ODY1MTczNTR8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Installing TensorFlow on Apple Silicon Macs"><p>Although Apple Silicon Macs have shown outstanding performance, compatibility issues still cannot be ignored for ordinary users. Installing TensorFlow on Apple Silicon is not as simple as typing <code>pip install tensorflow</code> on Intel Macs. However, numerous developers and Apple itself are working tirelessly to optimize Apple Silicon Macs. Now, installing TensorFlow on Apple Silicon has become much easier. This article will share the <a href="https://developer.apple.com/metal/tensorflow-plugin/?ref=localhost">recommended method</a> for installing TensorFlow on Apple Silicon Macs. We recommend bookmarking this article for future use!</p><h2 id="2-confirm-the-machine-type">2 Confirm the Machine Type</h2><p>This tutorial is suitable for Apple Silicon Macs. You can confirm the machine type by clicking the Apple logo on the top navigation bar and selecting &#x201C;About This Mac&#x201D;. Be sure to identify the Apple Silicon Mac.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/Mac_info.png" class="kg-image" alt="Installing TensorFlow on Apple Silicon Macs" loading="lazy"><figcaption>Please confirm that it is Apple Silicon Macs</figcaption></figure><h2 id="3-install-tensorflow">3 Install TensorFlow</h2><h3 id="31-install-conda">3.1 Install Conda</h3><p>First, download Conda: <a href="https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-MacOSX-arm64.sh?ref=localhost">https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-MacOSX-arm64.sh</a></p><p>The downloaded file will appear in the download folder by default (<code>~/Downloads/</code>). Open the terminal and run the following command:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/Terminal.png" class="kg-image" alt="Installing TensorFlow on Apple Silicon Macs" loading="lazy"><figcaption>Terminal on Mac</figcaption></figure><pre><code class="language-bash">chmod +x ~/Downloads/Miniforge3-MacOSX-arm64.sh
sh ~/Downloads/Miniforge3-MacOSX-arm64.sh
</code></pre><p>Follow the prompts to install, and then activate the Conda environment:</p><pre><code class="language-bash">source ~/miniforge3/bin/activate
</code></pre><h3 id="32-install-tensorflow-dependencies">3.2 Install TensorFlow Dependencies</h3><p>After activating the Conda environment, you can install the dependencies required by TensorFlow. The command is as follows:</p><pre><code class="language-bash">conda install -c apple tensorflow-deps
</code></pre><p>When installing a new version of TensorFlow, Apple recommends doing the following first:</p><pre><code class="language-bash"># Uninstall the existing tensorflow-macos and tensorflow-metal
python -m pip uninstall tensorflow-macos
python -m pip uninstall tensorflow-metal
# Upgrade tensorflow-deps
conda install -c apple tensorflow-deps --force-reinstall
</code></pre><h3 id="33-install-tensorflow">3.3 Install TensorFlow</h3><p>Continue to run the following command in the terminal:</p><pre><code class="language-bash">python -m pip install tensorflow-macos
</code></pre><h2 id="4-use-tensorflow">4 Use TensorFlow</h2><p>You can first install Jupyter Notebook, the command is as follows:</p><pre><code class="language-bash">conda install notebook -y
</code></pre><p>Then, start Jupyter Notebook to test whether TensorFlow has been successfully installed, and run the following command:</p><pre><code class="language-bash">jupyter notebook
</code></pre><p>Create a new notebook and import TensorFlow for inspection:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/TF_on_Apple_Silicon_Mac.png" class="kg-image" alt="Installing TensorFlow on Apple Silicon Macs" loading="lazy"><figcaption>TensorFlow on Apple Silicon Macs</figcaption></figure><h2 id="5-conclusion">5 Conclusion</h2><p>The above tutorial has been tested and is very easy to install. Do you have another reason to change to a new computer? It is said that the new Apple Silicon Mac will meet with us before November 2021. Let&apos;s go together!</p>]]></content:encoded></item><item><title><![CDATA[Customizing Models with tf.keras]]></title><description><![CDATA[<h2 id="1-introduction">1 Introduction</h2><p>tf.keras provides many convenient APIs for building deep learning models. However, some situations require custom layers and models. In this article, we will focus on customizing models and use the customization methods in TensorFlow 2.x to provide more flexibility for the solution.</p><h2 id="2-custom-layers">2 Custom Layers</h2><h3 id="21-creating-layers-without-weights">2.</h3>]]></description><link>http://localhost:2368/customizing-models-with-tf-keras/</link><guid isPermaLink="false">648635824543c30001eef8d1</guid><category><![CDATA[Tech]]></category><category><![CDATA[AI]]></category><category><![CDATA[Python]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Mon, 04 Oct 2021 05:00:00 GMT</pubDate><media:content url="http://localhost:2368/content/images/2023/06/TF_FullColor_Stacked-1.png" medium="image"/><content:encoded><![CDATA[<h2 id="1-introduction">1 Introduction</h2><img src="http://localhost:2368/content/images/2023/06/TF_FullColor_Stacked-1.png" alt="Customizing Models with tf.keras"><p>tf.keras provides many convenient APIs for building deep learning models. However, some situations require custom layers and models. In this article, we will focus on customizing models and use the customization methods in TensorFlow 2.x to provide more flexibility for the solution.</p><h2 id="2-custom-layers">2 Custom Layers</h2><h3 id="21-creating-layers-without-weights">2.1 Creating Layers without Weights</h3><p>When custom layers do not require weights, <code>tf.keras.layers.Lambda</code> can be very convenient, as shown below:</p><pre><code class="language-python">exponential_layer = keras.layers.Lambda(lambda x: tf.exp(x))
</code></pre><p>Then this custom layer can be used in the Sequential API and Functional API like other layers to build models. It can even be called like calling a Python function:</p><pre><code class="language-python">print(exponential_layer(2.0).numpy())
</code></pre><p>Output:</p><pre><code class="language-python">7.389056
</code></pre><h3 id="22-creating-layers-with-weights">2.2 Creating Layers with Weights</h3><p>If you need to create layers with weights, it is usually to inherit the <code>tf.keras.layers.Layer</code> class and override the <code>__init__</code>, <code>build</code>, and <code>call</code> methods, as shown below:</p><pre><code class="language-python">class Linear(keras.layers.Layer):
    def __init__(self, units=32):
        super(Linear, self).__init__()
        self.units = units

    def build(self, input_shape):
        self.w = self.add_weight(
            shape=(input_shape[-1], self.units),
            initializer=&quot;random_normal&quot;,
            trainable=True,
        )
        self.b = self.add_weight(
            shape=(self.units,), initializer=&quot;random_normal&quot;, trainable=True
        )

    def call(self, inputs):
        return tf.matmul(inputs, self.w) + self.b
</code></pre><p>The custom layer can be called like the built-in layers in tf.keras:</p><pre><code class="language-python">input_ = Input((1,))
output = Linear(units=1)(input_)
model = Model(input_, output)
model.compile(optimizer=&apos;Adam&apos;, loss=&quot;mse&quot;)
model.summary()
</code></pre><p>Output:</p><pre><code class="language-python">Model: &quot;model_1&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, 1)]               0         
_________________________________________________________________
linear_1 (Linear)            (None, 1)                 2         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
</code></pre><p>Please note that if you want to serialize the custom layer as part of the Functional API model, you need to implement the <code>get_config()</code> method. The <code>__init__()</code> method of the base Layer class accepts some keyword arguments, especially <code>name</code> and <code>dtype</code>. It is best to pass these arguments to the parent class in <code>__init__()</code> and include them in the layer&apos;s configuration, <a>as shown below</a>:</p><pre><code class="language-python">class Linear(keras.layers.Layer):
    def __init__(self, units=32, **kwargs):
        super(Linear, self).__init__(**kwargs)
        self.units = units

    def build(self, input_shape):
        self.w = self.add_weight(
            shape=(input_shape[-1], self.units),
            initializer=&quot;random_normal&quot;,
            trainable=True,
        )
        self.b = self.add_weight(
            shape=(self.units,), initializer=&quot;random_normal&quot;, trainable=True
        )

    def call(self, inputs):
        return tf.matmul(inputs, self.w) + self.b

    def get_config(self):
        config = super(Linear, self).get_config()
        config.update({&quot;units&quot;: self.units})
        return config

</code></pre><p>If the behavior of the custom layer is different during training and inference, such as with Dropout or BatchNormalization layers, <code>training</code> parameters need to be added to the <code>call</code> function to distinguish the behavior of the model under different running states, as shown below:</p><pre><code class="language-python">class CustomDropout(keras.layers.Layer):
    def __init__(self, rate, **kwargs):
        super(CustomDropout, self).__init__(**kwargs)
        self.rate = rate

    def call(self, inputs, training=None):
        if training:
            return tf.nn.dropout(inputs, rate=self.rate)
        return inputs
</code></pre><h3 id="23-customizing-losses-and-metrics">2.3 Customizing Losses and Metrics</h3><p>When customizing losses, use labels and predicted values as parameters, and then use TensorFlow operators to calculate the loss for each instance.</p><pre><code class="language-python">def huber_fn(y_true,y_pred):
  error=y_true-y_pred
  is_small_error=tf.abs(error)&lt;1
  squared_loss=tf.square(error)/2
  linear_loss=tf.abs(error)-0.5

return tf.where(is_small_error,squared_loss,linear_loss)
</code></pre><p>When customizing evaluation metrics, you can inherit the <code>tf.keras.metrics.Metric</code> class and override the <code>__init__</code>, <code>update_state</code>, and <code>result</code> methods, <a href="https://tf.wiki/zh_hans/basic/models.html?ref=localhost#id26">as shown in the example</a>:</p><pre><code class="language-python">class SparseCategoricalAccuracy(tf.keras.metrics.Metric):
    def __init__(self):
        super().__init__()
        self.total = self.add_weight(name=&apos;total&apos;, dtype=tf.int32, initializer=tf.zeros_initializer())
        self.count = self.add_weight(name=&apos;count&apos;, dtype=tf.int32, initializer=tf.zeros_initializer())

    def update_state(self, y_true, y_pred, sample_weight=None):
        values = tf.cast(tf.equal(y_true, tf.argmax(y_pred, axis=-1, output_type=tf.int32)), tf.int32)
        self.total.assign_add(tf.shape(y_true)[0])
        self.count.assign_add(tf.reduce_sum(values))

    def result(self):
        return self.count / self.total
</code></pre><p>The <code>update_state()</code> method works when the instance of the custom evaluation metric class is called, receiving labels, predicted values, and other custom parameters in a batch to update defined variables. The <code>result()</code> method calculates and returns the final result, which is executed after the <code>update_state()</code> method.</p><h2 id="3-conclusion">3 Conclusion</h2><p>The above examples introduce how to customize keras models, which can add flexibility to daily workflows. In practical work, you need to repeatedly scrutinize and ensure that there are no errors.</p><p>I hope this sharing will help you. Welcome to leave a message in the comment area for discussion!</p>]]></content:encoded></item><item><title><![CDATA[Introduction to various Keras Callbacks]]></title><description><![CDATA[<h2 id="1-introduction">1 Introduction</h2><p>In tensorflow.keras, callbacks can run along with the model&apos;s life cycle during <code>fit</code>, <code>evaluate</code> and <code>predict</code> processes. At present, tensorflow.keras has built many types of callbacks available for users to prevent overfitting, visualize the training process, debug, save model checkpoints, and generate TensorBoard, etc.</p>]]></description><link>http://localhost:2368/introduction-to-various-keras-callbacks/</link><guid isPermaLink="false">648634104543c30001eef8c1</guid><category><![CDATA[Tech]]></category><category><![CDATA[AI]]></category><category><![CDATA[Python]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sat, 02 Oct 2021 05:00:00 GMT</pubDate><media:content url="http://localhost:2368/content/images/2023/06/TF_FullColor_Stacked.png" medium="image"/><content:encoded><![CDATA[<h2 id="1-introduction">1 Introduction</h2><img src="http://localhost:2368/content/images/2023/06/TF_FullColor_Stacked.png" alt="Introduction to various Keras Callbacks"><p>In tensorflow.keras, callbacks can run along with the model&apos;s life cycle during <code>fit</code>, <code>evaluate</code> and <code>predict</code> processes. At present, tensorflow.keras has built many types of callbacks available for users to prevent overfitting, visualize the training process, debug, save model checkpoints, and generate TensorBoard, etc. Through this article, we will learn how to use various callbacks in tensorflow.keras and how to customize callbacks.</p><h2 id="2-using-callbacks">2 Using Callbacks</h2><p>Using callbacks is very simple. First, define the callbacks, then pass the defined callbacks to the <code>callbacks</code> parameter in <code>model.fit()</code>, <code>model.evaluate()</code>, and <code>model.predict()</code>.</p><p>Take the most common <code>ModelCheckpoint</code> as an example. The usage process is as follows:</p><pre><code class="language-python">...
model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
    filepath=filePath,
    save_weights_only=True,
    monitor=&apos;val_accuracy&apos;,
    mode=&apos;max&apos;)

model.fit(x, y, callbacks=model_checkpoint_callback)
</code></pre><p>In this way, when the model is trained, the model checkpoints will be stored in the corresponding position for later use. In addition to ModelCheckpoint, there are many other types of callbacks available for use in TensorFlow 2.0. Let&apos;s explore them.</p><h3 id="21-earlystopping">2.1 EarlyStopping</h3><p>This callback can monitor the specified evaluation metric. During the training process, when the evaluation metric stops increasing, the training will end early to prevent overfitting. Its default parameters are as follows:</p><pre><code class="language-python">tf.keras.callbacks.EarlyStopping(monitor=&apos;val_loss&apos;,
        min_delta=0,
        patience=0,
        verbose=0,
        mode=&apos;auto&apos;,
        baseline=None,
        restore_best_weights=False)
</code></pre><p>The parameters are as follows:</p><ul><li>monitor: the evaluation metric monitored by callbacks.</li><li>min_delta: the smallest metric improvement that will be counted.</li><li>patience: the number of epochs to wait before stopping training when the evaluation metric stops improving.</li><li>verbose: whether to print logs.</li><li>mode: the mode of monitoring metrics, such as whether to monitor if the metric is decreasing, increasing, or automatically inferred based on the metric name.</li><li>baseline: the baseline of the monitored metric. When the result of the model training is below the standard line, the training will stop.</li><li>restore_best_weights: whether to restore the model from the epoch with the best training effect. If set to False, the model weights will be restored from the last step.</li></ul><h3 id="22-learningratescheduler">2.2 LearningRateScheduler</h3><p>This callback can adjust the learning rate during the model training process. Generally, the learning rate can be appropriately reduced as the number of training increases to help the model converge to the global optimum. Therefore, this callback needs to be used together with a learning rate scheduler. At the beginning of each epoch, the schedule function will obtain the latest learning rate and use it in the current epoch:</p><pre><code class="language-python">tf.keras.callbacks.LearningRateScheduler(
    schedule, verbose=0
)

# The scheduling function calls the initial learning rate before 10 epochs, and then the learning rate decreases exponentially
def scheduler(epoch, lr):
  if epoch &lt; 10:
    return lr
  else:
    return lr * tf.math.exp(-0.1)

model = tf.keras.models.Sequential([tf.keras.layers.Dense(10)])
model.compile(tf.keras.optimizers.SGD(), loss=&apos;mse&apos;)
callback = tf.keras.callbacks.LearningRateScheduler(scheduler)
history = model.fit(np.arange(100).reshape(5, 20), np.zeros(5),
                    epochs=15, callbacks=[callback], verbose=0)

</code></pre><h3 id="23-reducelronplateau">2.3 ReduceLROnPlateau</h3><p>Compared with LearningRateScheduler, ReduceLROnPlateau does not adjust the learning rate according to the pre-set schedule. It reduces the learning rate when the evaluation metric stops improving.</p><pre><code class="language-python">tf.keras.callbacks.ReduceLROnPlateau(
    monitor=&apos;val_loss&apos;, factor=0.1, patience=10, verbose=0,
    mode=&apos;auto&apos;, min_delta=0.0001, cooldown=0, min_lr=0, **kwargs
)
</code></pre><p>Important parameters are:</p><ul><li>factor: the degree of learning rate reduction, new_lr = lr * factor.</li><li>cooldown: the number of epochs to wait before monitoring the evaluation metric again.</li><li>min_lr: the minimum allowed learning rate.</li></ul><h3 id="24-tensorboard">2.4 TensorBoard</h3><p>TensorBoard can conveniently display the model architecture and the training process. This callback can generate TensorBoard logs, and you can view the visualization results in TensorBoard after the training is completed.</p><pre><code class="language-python">tf.keras.callbacks.TensorBoard(
    log_dir=&apos;logs&apos;, histogram_freq=0, write_graph=True,
    write_images=False, write_steps_per_second=False, update_freq=&apos;epoch&apos;,
    profile_batch=2, embeddings_freq=0, embeddings_metadata=None, **kwargs
)
</code></pre><p>Important parameters are:</p><ul><li>log_dir: the path to the log output.</li><li>histogram_freq: the frequency of calculating the activation function and weight histograms. If set to 0, the histograms will not be calculated.</li><li>write_graph: whether to visualize the graph in TensorBoard.</li><li>update_freq: a string that can be &apos;batch&apos;, &apos;epoch&apos;, or an integer. Loss and evaluation metrics will be written to TensorBoard after the specified processing completes. If set to an integer, it means that the loss and evaluation metrics will be written to TensorBoard after the specified number of samples have been trained.</li><li>write_images: whether to write weight histograms and other variables as images.</li><li>write_steps_per_second: whether to write the number of steps per second during processing.</li><li>profile_batch: the batch for profiling. The default value is 2, and -1 means that all batches will be profiled.</li></ul><h3 id="25-csvlogger">2.5 CSVLogger</h3><p>As the name suggests, this callback can write the training process to a CSV file.</p><pre><code class="language-python">tf.keras.callbacks.CSVLogger(
    filename, separator=&apos;,&apos;, append=False
)
</code></pre><p>Important parameters:</p><ul><li>append: whether to continue writing logs to existing files.</li></ul><h3 id="26-terminateonnan">2.6 TerminateOnNaN</h3><p>Stop training when the loss becomes NaN.</p><pre><code class="language-python">tf.keras.callbacks.TerminateOnNaN()
</code></pre><h3 id="27-custom-callback">2.7 Custom Callback</h3><p>In addition to the above callbacks, there are other callbacks available on the <a>TensorFlow official website</a>. When using multiple callbacks, you can pass multiple callbacks into a list, or use <a href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/CallbackList?ref=localhost">tf.keras.callbacks.CallbackList</a>. In addition, you can also customize callbacks, which requires inheriting <code>keras.callbacks.Callback</code> and then overriding methods at different training stages.</p><pre><code class="language-python">training_finished = False

class MyCallback(tf.keras.callbacks.Callback):
  def on_train_end(self, logs=None):
    global training_finished
    training_finished = True

model = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(1,))])
model.compile(loss=&apos;mean_squared_error&apos;)
model.fit(tf.constant([[1.0]]), tf.constant([[1.0]]),
          callbacks=[MyCallback()])

assert training_finished == True
</code></pre><h2 id="3-conclusion">3 Conclusion</h2><p>This article summarizes some commonly used tf.keras.callbacks. In actual work, please use them as needed and check the official documentation of tf.keras.callbacks to confirm the parameter values.</p><p>Hope this sharing is helpful to you, and welcome to leave a comment in the comment section to discuss!</p>]]></content:encoded></item><item><title><![CDATA[Understanding Python Closures]]></title><description><![CDATA[<h2 id="1-introduction">1 Introduction</h2><p>When working with Python in daily work, you may have encountered code like this:</p><pre><code class="language-python">def make_counter():
    # Outer closure function
    count = 0
    def counter():
      # Nested function
        nonlocal count
        count += 1
        return count

    return counter
</code></pre><p>Why define functions like this - with one function inside another, and the outer</p>]]></description><link>http://localhost:2368/tips-for-common-operations-on-python-dictionaries-co/</link><guid isPermaLink="false">648632ef4543c30001eef8aa</guid><category><![CDATA[Tech]]></category><category><![CDATA[Python]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Tue, 21 Sep 2021 05:00:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1514428631868-a400b561ff44?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDE5fHxweXRob258ZW58MHx8fHwxNjg2NTE1NTMwfDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<h2 id="1-introduction">1 Introduction</h2><img src="https://images.unsplash.com/photo-1514428631868-a400b561ff44?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDE5fHxweXRob258ZW58MHx8fHwxNjg2NTE1NTMwfDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Understanding Python Closures"><p>When working with Python in daily work, you may have encountered code like this:</p><pre><code class="language-python">def make_counter():
    # Outer closure function
    count = 0
    def counter():
      # Nested function
        nonlocal count
        count += 1
        return count

    return counter
</code></pre><p>Why define functions like this - with one function inside another, and the outer function returning the inner function as its output? What are the benefits of this approach? In this article, we will uncover the mysterious veil of closures.</p><h2 id="2-key-points-of-closures">2 Key points of closures</h2><p>A closure is a function that extends the scope of a function, referring to a non-global variable (such as count in the example above) that is not defined in the function. By adding nonlocal, the variable is marked as a free variable (nonlocal keyword was added in Python 3), allowing the nested function to modify the immutable variable outside the scope.</p><p>When we call make_counter, it returns a counter function object. Each time we call the counter, it updates count, as shown below:</p><pre><code class="language-python"># Run the closure function
counter = make_counter()
print(counter())
print(counter())
</code></pre><p>Output:</p><pre><code class="language-python">1
2
</code></pre><p>In this example, one thing that needs to be expanded is the storage location of the historical value of count. Count is a local variable in the make_counter function, and its initial value is 0. However, when counter is called, the make_counter function has already been returned, and the local scope should no longer exist.</p><p>In the counter function, count is a free variable, and the counter function implements the binding of this variable. We can check the names of stored local variables and free variables using the <strong>code</strong> attribute (which represents the compiled function definition body) in Python. For example:</p><pre><code class="language-python"># View free variables
counter.__code__.co_freevars
</code></pre><p>Output:</p><pre><code>(&apos;count&apos;,)
</code></pre><p>The binding of count is in the <strong>closure</strong> attribute of the returned counter function, where each element of <strong>closure</strong> corresponds to a name in <code>counter.__code__.co_freevars</code>. These elements are cell objects, and their stored values can be accessed through the cell_contents attribute, as shown below:</p><pre><code class="language-python">counter.__closure__[0].cell_contents
</code></pre><p>Output:</p><pre><code>2
</code></pre><p>Closures can solve lightweight problems very concisely and intuitively. If we were to use a <code>class</code> to implement the functionality above, it would look like this:</p><pre><code class="language-python"># Define a counter using a class, starting from 0
class Counter:
    def __init__(self):
        self.count = 0

    def __call__(self):
        self.count += 1
        return self.count

counter = Counter()
print(counter())
print(counter())
</code></pre><p>Output:</p><pre><code class="language-python">1
2
</code></pre><h2 id="3-summary">3 Summary</h2><p>A closure is a function that retains the binding of free variables that were present when the function was defined, so even if the scope no longer exists after the function is returned, the bindings can still be used. Closures can easily implement simple class functionality, and there are many Python &quot;magic&quot; functions that can be implemented based on this, such as decorators, which we will explore next time!</p><p>I hope this article has been helpful to you, and feel free to discuss in the comments!</p>]]></content:encoded></item><item><title><![CDATA[Overview of SnowFlake Architecture]]></title><description><![CDATA[<h2 id="1-introduction">1 Introduction</h2><p>SnowFlake, as a highly popular data warehousing application in recent years, has gained the favor of many users and investors. In my daily work, I also often use SnowFlake for analysis, so I have done some research on its underlying operation mechanism. Today, I will talk to you</p>]]></description><link>http://localhost:2368/overview-of-snowflake-architecture/</link><guid isPermaLink="false">648631d64543c30001eef87d</guid><category><![CDATA[Tech]]></category><category><![CDATA[Analytics]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sat, 11 Sep 2021 05:00:00 GMT</pubDate><media:content url="http://localhost:2368/content/images/2023/06/sf.png" medium="image"/><content:encoded><![CDATA[<h2 id="1-introduction">1 Introduction</h2><img src="http://localhost:2368/content/images/2023/06/sf.png" alt="Overview of SnowFlake Architecture"><p>SnowFlake, as a highly popular data warehousing application in recent years, has gained the favor of many users and investors. In my daily work, I also often use SnowFlake for analysis, so I have done some research on its underlying operation mechanism. Today, I will talk to you about the main architecture and working principles of SnowFlake.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://user-images.githubusercontent.com/26101303/132982228-360bd20b-ed29-4ff6-84d3-c77d74169c9f.png" class="kg-image" alt="Overview of SnowFlake Architecture" loading="lazy"><figcaption>SnowFlake stock price</figcaption></figure><h2 id="2-main-features-of-snowflake">2 Main Features of SnowFlake</h2><ul><li>Security and Data Protection: SnowFlake supports multiple authentication methods, such as Multi-Factor Authentication (MFA), Federal Authentication, Single Sign-on (SSO), and OAuth. Communication between clients and servers is protected by <a href="https://en.wikipedia.org/wiki/Transport_Layer_Security?ref=localhost">TLS</a>.</li><li>Support Standard SQL and Many Extended SQL Features: SnowFlake supports most SQL data definition language (Data Definition Language) and data manipulation language (Data Manipulation Language), so there is no need to worry about finding corresponding operations when doing data analysis.</li><li>SnowFlake supports software clients for connection, and also provides interfaces for various programming languages such as Python connector, Spark connector, Node.js driver, .NET driver, etc.</li><li>Convenient Sharing Functionality: Users can easily share data and query statements with other users.</li></ul><h2 id="3-snowflake-architecture">3 SnowFlake Architecture</h2><p>The SnowFlake architecture combines the advantages of Shared-Disk architecture and Shared-Nothing architecture, and consists of three different layers: the Storage Layer, the Compute Layer, and the Cloud Services Layer. The architecture diagrams of these two types are shown below:</p><h3 id="31-shared-disk-architecture-diagram">3.1 Shared-Disk Architecture Diagram</h3><p>This is commonly used in traditional databases. It has a storage layer that all nodes in the cluster can access, and the computing nodes in the cluster do not have their own storage. They all access the central storage layer to retrieve data and perform processing. The cluster control software is used to monitor and manage data processing. All nodes obtain the same data, so it is absolutely forbidden for two or more nodes to update the same data at the same time.</p><p>This architecture is not conducive to performance, and lacks scalability. Applications that require frequent data updates are not suitable for this type of architecture because the Shared-Disk lock mechanism will impede them.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://user-images.githubusercontent.com/26101303/132982226-1ccaf053-bddd-4c1c-933a-f555eebd1e29.png" class="kg-image" alt="Overview of SnowFlake Architecture" loading="lazy"><figcaption>Shared-Disk Architecture</figcaption></figure><h3 id="32-shared-nothing-architecture-diagram">3.2 Shared-Nothing Architecture Diagram</h3><p>As the name suggests, in the Shared-Nothing architecture, each node in the cluster has its own separate computing resources and storage space, and data can be stored in various nodes by partition. When processing user requests, the router assigns the request to the appropriate node for calculation. When a calculation error occurs, the processing process can be taken over by another node to ensure stable and correct processing of user requests. This architecture is very suitable for applications with a large amount of data reads, such as data warehouses.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://user-images.githubusercontent.com/26101303/132982223-b99b67f5-3018-4f47-b03f-ac1f165f76b9.png" class="kg-image" alt="Overview of SnowFlake Architecture" loading="lazy"><figcaption>Shared-Nothing Architecture</figcaption></figure><h3 id="33-snowflake-architecture-diagram">3.3 SnowFlake Architecture Diagram</h3><p>SnowFlake uses three different layers to build the application: the storage layer, the compute layer, and the cloud services layer. The diagram is shown below:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://user-images.githubusercontent.com/26101303/132982227-9cb5fbcd-cb8b-4c53-8f8d-448abddb2663.png" class="kg-image" alt="Overview of SnowFlake Architecture" loading="lazy"><figcaption>SnowFlake Architecture</figcaption></figure><p>The Storage Layer is responsible for optimizing, compressing, and storing data in multiple tiny fragments. Data is stored in row column format and managed in a manner similar to Shared-Disk. Compute nodes retrieve and process data by connecting to the Storage Layer, which is independent of other resources. SnowFlake is deployed in the cloud, so its super large distributed storage system can ensure high performance, stability, availability, capacity, and scalability.</p><p>The Compute Layer uses virtual warehouses (based on virtual machines) to run query statements. The Compute Layer and the Storage Layer are designed to be separate, and SnowFlake implements intelligent caching mechanisms between them to optimize resource utilization and reduce unnecessary interaction between the Compute Layer and the Storage Layer. Virtual warehouses come in different sizes and can be used to process requests with different performance requirements. Each virtual warehouse is independent of each other, so compute resources are not shared. The advantages of this design are:</p><ul><li>Virtual warehouses can be created or deleted at any time. It is also easy to expand the computing resources of virtual warehouses without affecting the calculation of query statements.</li><li>Virtual warehouses can be easily stopped or restarted, suitable for long periods of time without queries or need to participate in queries after a period of dormancy.</li><li>Virtual warehouse cluster size can be automatically changed very easily.</li></ul><p>The Cloud Services Layer is responsible for user information authentication, cluster management, security and encryption, metadata management of data, optimization of query statements, etc. These tasks are all completed by the Compute Layer. Common processing content examples include:</p><ul><li>User login</li><li>After the query statement is submitted, it will first go through the optimizer of the Cloud Services Layer, and then be passed to the Compute Layer for processing</li><li>Metadata required for optimizing queries and filtering data is also stored at this level</li></ul><p>The three-layer architecture of SnowFlake can be independently expanded, but SnowFlake only charges for the Storage Layer and the Compute Layer, as the Cloud Services Layer is processed in the Compute Node. The advantage of independent expansion is obvious. If more data is needed, the Storage Layer can be individually expanded. If stronger computing performance is required, the Compute Layer can be individually expanded. Refer to the official SnowFlake <a href="https://docs.snowflake.com/en/user-guide/intro-key-concepts.html?ref=localhost">Architecture Guide</a> for more details.</p><h2 id="4-conclusion">4 Conclusion</h2><p>After understanding the SnowFlake architecture, I believe you can better understand why so many companies choose SnowFlake. Its cloud-based architecture provides efficient, secure, stable, and cost-effective solutions for many enterprises. As a data analyst, I have personally experienced that SnowFlake is indeed easier to use than many traditional data warehouses.</p>]]></content:encoded></item><item><title><![CDATA[Tips for Common Operations on Python Dictionaries]]></title><description><![CDATA[<h2 id="1-introduction">1 Introduction</h2><p>In the previous article, we reviewed <a href="http://localhost:2368/tips-for-common-operations-on-python-lists">common operations on Python lists</a>. As a commonly used data type, lists play a very important role in daily work. In this article, we will continue to talk about another commonly used data type in Python - dictionaries (Dict).</p><p>Dictionaries can be</p>]]></description><link>http://localhost:2368/tips-for-common-operations-on-python-dictionaries/</link><guid isPermaLink="false">6486305b4543c30001eef862</guid><category><![CDATA[Tech]]></category><category><![CDATA[Python]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sat, 21 Aug 2021 05:00:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1514428631868-a400b561ff44?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDE5fHxweXRob258ZW58MHx8fHwxNjg2NTE1NTMwfDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<h2 id="1-introduction">1 Introduction</h2><img src="https://images.unsplash.com/photo-1514428631868-a400b561ff44?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDE5fHxweXRob258ZW58MHx8fHwxNjg2NTE1NTMwfDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Tips for Common Operations on Python Dictionaries"><p>In the previous article, we reviewed <a href="http://localhost:2368/tips-for-common-operations-on-python-lists">common operations on Python lists</a>. As a commonly used data type, lists play a very important role in daily work. In this article, we will continue to talk about another commonly used data type in Python - dictionaries (Dict).</p><p>Dictionaries can be defined using the <code>dict()</code> method or using curly braces, such as <code>name2code = {&apos;Tony&apos;:1, &apos;Kevin&apos;:2, &apos;Luis&apos;:3}</code>. If you want to add elements, you can use the key-value assignment pattern: <code>name2code[&apos;Nick&apos;] = 0</code>. It is easy to see that, unlike lists, dictionaries do not use integers as subscripts. Let&apos;s take a look at the commonly used methods of dictionaries.</p><h2 id="2-common-dictionary-methods">2 Common Dictionary Methods</h2><h3 id="21-indexing">2.1 Indexing</h3><p>Since dictionaries are in the form of key-value pairs, you can use the key to index the value you need. For example:</p><pre><code class="language-python">print(name2code[&apos;Nick&apos;] )
</code></pre><p>Output:</p><pre><code class="language-python">0
</code></pre><p>Similarly to lists, you can use the <code>in</code> operator to check whether the dictionary contains the key you want to find. It is worth noting that the implementation of the <code>in</code> operator in lists and dictionaries is different. Lists use a search algorithm, so when the list becomes longer, the search time will also become longer. But dictionaries use a hash table algorithm, so regardless of how many key-value pairs there are in the dictionary, the <code>in</code> operator takes almost the same amount of time.</p><pre><code class="language-python">print(&apos;Nick&apos; in name2code)
</code></pre><p>Output:</p><pre><code class="language-python">True
</code></pre><p>If you want to see whether a value is in the dictionary, you can use the <code>values()</code> method to extract the values from the dictionary and use the <code>in</code> operator to check:</p><pre><code class="language-python">values = name2code.values()
print(0 in values)
</code></pre><p>Output:</p><pre><code class="language-python">True
</code></pre><h3 id="22-deleting-elements">2.2 Deleting Elements</h3><p>The method for deleting elements from a dictionary is similar to that for a list:</p><ul><li>To clear a dictionary: <code>name2code.clear()</code>, note that the <code>clear()</code> method has no return value</li><li>Remove the key-value pair associated with the key k and return the corresponding value: <code>name2code.pop(k, [default])</code></li><li>Return the last key-value pair added and remove it: <code>name2code.popitem()</code></li></ul><h3 id="23-looping">2.3 Looping</h3><p>You can use a for loop to iterate through the keys of a dictionary. Please note that because the keys are hashable, their appearance does not follow a specific order. The following code may have a different output order on your computer (Note: Python 3.6 and later versions retain the order in which the key-value pairs were added, so the result is determined):</p><pre><code class="language-python">for i in name2code:
    print(i, name2code[i])
</code></pre><p>Output:</p><pre><code class="language-python">Tony 1
Kevin 2
Luis 3
Nick 0
</code></pre><p>If you want to iterate through both the key and value, you can use the <code>items()</code> method:</p><pre><code class="language-python">for k,v in name2code.items():
    print(k,v)
</code></pre><p>Output:</p><pre><code class="language-python">Tony 1
Kevin 2
Luis 3
Nick 0
</code></pre><h3 id="24-reverse-lookup">2.4 Reverse Lookup</h3><p>For a dictionary, the operation of using a key to find a value has been introduced above. If you want to use a value to find its associated key, then you need to perform a reverse lookup. Note that a <code>raise</code> statement is used here to throw an exception, which is used to display the value of the parameter being searched.</p><pre><code class="language-python">def reversed_lookup(d, v):
    for i in d:
        if d[i] == v:
            return i
    raise ValueError(&quot;The value being searched for is not in the dictionary&quot;)

reversed_lookup(name2code,5)
</code></pre><p>Output:</p><pre><code class="language-python">---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-33-832e824fe6b4&gt; in &lt;module&gt;
----&gt; 1 reversed_lookup(name2code,5)

&lt;ipython-input-32-be75152f6e58&gt; in reversed_lookup(d, v)
      4             return i
      5
----&gt; 6     raise ValueError(&quot;The value being searched for is not in the dictionary&quot;)

ValueError: The value being searched for is not in the dictionary
</code></pre><h3 id="25-dictionary-comprehension">2.5 Dictionary Comprehension</h3><p>Starting from Python 2.7, list comprehension and generator expressions have also been ported to dictionaries. For example:</p><pre><code class="language-python">code2name = {code:name for name,code in name2code.items() if code &lt; 2}
print(code2name)
</code></pre><p>Output:</p><pre><code class="language-python">{1: &apos;Tony&apos;, 0: &apos;Nick&apos;}
</code></pre><h2 id="3-variants-of-dictionaries">3 Variants of Dictionaries</h2><p>In addition to <code>dict</code>, there are several other mapping types in the <code>collections</code> module of the Python standard library:</p><ul><li><code>collections.OrderedDict</code>: This type keeps the order of keys when they are added, so the iteration order of keys remains consistent. Please note that if you define an ordered dictionary and do not insert any data after that, the original key-value pairs are still unordered, just like a regular dictionary.</li><li><code>collections.ChainMap</code>: This type can hold multiple different mapping objects. When a key lookup operation is performed, these objects are searched one by one until the corresponding key is found. This is commonly used for managing dictionaries that represent different scopes and contexts.</li><li><code>collections.Counter</code>: As the name suggests, this is a counter. When a key is updated, the counter is also updated. It is commonly used to count elements in a hash table or as a multiset (a set where elements occur multiple times).</li><li><code>colllections.UserDict</code>: This class is mainly used for inheritance by users. Inheriting from this class is more convenient than inheriting from <code>dict</code> because the methods of built-in types like <code>dict</code> usually ignore user-overridden methods, causing unexpected troubles, as detailed in Chapter 12 of <a href="https://book.douban.com/subject/27028517/?ref=localhost">Fluent Python</a>.</li></ul><h2 id="4-summary">4 Summary</h2><p>The above knowledge points are commonly used in daily work. The following content also covers the summary of many years of practical experience of Python programmers. Let&apos;s review again:</p><ul><li>The keys of a dictionary must be hashable. This means that the hash value of an object remains unchanged during its lifetime, and the object must implement the <code>__hash__</code> method to support equality checks using the <code>__eq__</code> method.</li><li>Dictionaries consume a significant amount of memory. This is because dictionaries use hash tables, which must be sparse, resulting in low space utilization. If the data size is huge, it is recommended to use tuples or lists.</li><li>Key lookup in dictionaries is very efficient. As long as the dictionary can fit in memory, the speed of key lookup does not slow down with increasing data size. However, the fast speed comes at the cost of larger memory usage.</li><li>Adding new keys to a dictionary may change the order of existing keys. The specific reason depends on the implementation of the dictionary. It is recommended not to iterate and modify a dictionary simultaneously. It&apos;s better to divide it into two steps: iterate to find the content that needs to be modified and record it, then modify the original dictionary after iteration.</li></ul><p>While reviewing these knowledge points, I have gained new understanding and insights. I hope this content is helpful to you too!</p>]]></content:encoded></item><item><title><![CDATA[Tips for Common Operations on Python Lists]]></title><description><![CDATA[<h2 id="1-preface">1. Preface</h2><p>In the previous article, we reviewed the <a href="http://localhost:2368/tips-for-common-operations-with-python-tuples">common operations on Python tuples</a>, in this article, let&apos;s talk about another common data type in Python: lists.</p><p>Like tuples, lists are also sequences created by square brackets <code>[]</code>. The values in the list are commonly referred to as elements,</p>]]></description><link>http://localhost:2368/tips-for-common-operations-on-python-lists/</link><guid isPermaLink="false">64862fcd4543c30001eef850</guid><category><![CDATA[Tech]]></category><category><![CDATA[Python]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sat, 14 Aug 2021 05:00:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1514428631868-a400b561ff44?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDE5fHxweXRob258ZW58MHx8fHwxNjg2NTE1NTMwfDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<h2 id="1-preface">1. Preface</h2><img src="https://images.unsplash.com/photo-1514428631868-a400b561ff44?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDE5fHxweXRob258ZW58MHx8fHwxNjg2NTE1NTMwfDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Tips for Common Operations on Python Lists"><p>In the previous article, we reviewed the <a href="http://localhost:2368/tips-for-common-operations-with-python-tuples">common operations on Python tuples</a>, in this article, let&apos;s talk about another common data type in Python: lists.</p><p>Like tuples, lists are also sequences created by square brackets <code>[]</code>. The values in the list are commonly referred to as elements, and the data type of the elements can be different. For example, <code>test_list = [0,1,1,&apos;a&apos;,&apos;b&apos;]</code> can successfully create a list.</p><p>Unlike tuples, lists are mutable sequences, so the operations available for sequences will be more flexible. Next, we will review the most commonly used operations on lists.</p><h2 id="2-common-operations-on-lists">2. Common operations on lists</h2><h3 id="21-traversal">2.1 Traversal</h3><p>Taking the list <code>people = [&apos;Adam&apos;,&apos;Nick&apos;,&apos;Tony&apos;]</code> as an example, we can use a for loop to traverse:</p><pre><code class="language-python">for i in people:
  print(i)
</code></pre><p>When updating the list, using an index to traverse will be more convenient:</p><pre><code class="language-python">for i in range(len(people)):
  people[i] += &apos;_suffix&apos;
</code></pre><h3 id="22-slicing">2.2 Slicing</h3><p>Like tuples, you can get the elements of a list by slicing (the index in Python starts from 0):</p><pre><code class="language-python">print(people[:2])
</code></pre><p>Output:</p><pre><code>[&apos;Adam&apos;,&apos;Nick&apos;]
</code></pre><h3 id="23-deleting-elements">2.3 Deleting Elements</h3><p>a. The <code>pop</code> method can return the value to be deleted, and you can use an index to delete or delete the last element: <code>a = people.pop(2)</code> or <code>a = people.pop()</code>, the value of <code>a</code> will be <code>&apos;Tony&apos;</code>, and the original list will delete the corresponding element.</p><p>b. If you don&apos;t need the deleted value, <code>del</code> is a good method: <code>del people[0]</code>, then the list <code>people</code> will become <code>[&apos;Nick&apos;,&apos;Tony&apos;]</code>.</p><p>c. The <code>remove</code> method will delete the first required element in the list. For example, after the <code>test_list.remove(1)</code> operation, the list will become <code>test_list = [0,1,&apos;a&apos;,&apos;b&apos;]</code>. Note that the <code>remove</code> method does not return any value.</p><h3 id="24-interaction-between-lists-and-strings">2.4 Interaction between Lists and Strings</h3><p>Lists and strings can be flexibly converted. For example, convert a string to a list:</p><pre><code class="language-python"># Convert string to list
name = &apos;Adam is very cool&apos;
name_list_1 = list(name)
print(name_list_1)

# The split method can split the string using a delimiter
name_list_2 = name.split()
print(name_list_2)
</code></pre><p>Output:</p><pre><code>[&apos;A&apos;, &apos;d&apos;, &apos;a&apos;, &apos;m&apos;, &apos; &apos;, &apos;i&apos;, &apos;s&apos;, &apos; &apos;, &apos;v&apos;, &apos;e&apos;, &apos;r&apos;, &apos;y&apos;, &apos; &apos;, &apos;c&apos;, &apos;o&apos;, &apos;o&apos;, &apos;l&apos;]

[&apos;Adam&apos;, &apos;is&apos;, &apos;very&apos;, &apos;cool&apos;]
</code></pre><p>Sometimes you need to merge a list into a string, the <code>join</code> method is very useful:</p><pre><code class="language-python"># Join the elements in the list with spaces into a new string
print(&apos; &apos;.join([&apos;Adam&apos;, &apos;is&apos;, &apos;very&apos;, &apos;cool&apos;]))
</code></pre><p>Output:</p><pre><code>&apos;Adam is very cool&apos;
</code></pre><h3 id="25-aliases-of-lists">2.5 Aliases of Lists</h3><p>This is a point that is easy to make a mistake. In the following code, two variables are exactly the same, changing one will also change the value of the other:</p><pre><code class="language-python"># alias is an alias for the list name
name = [&apos;Adam&apos;, &apos;is&apos;, &apos;very&apos;, &apos;cool&apos;]
alias = name
alias.pop()
print(name)
</code></pre><p>Output:</p><pre><code class="language-python">[&apos;Adam&apos;, &apos;is&apos;, &apos;very&apos;]
</code></pre><p>Therefore, when you want to use two independent lists, try to use separate assignment statements or shallow copies:</p><pre><code class="language-python">name = [&apos;Adam&apos;, &apos;is&apos;, &apos;very&apos;, &apos;cool&apos;]

# Create a list with the same values
name_2 = [&apos;Adam&apos;, &apos;is&apos;, &apos;very&apos;, &apos;cool&apos;]
# Shallow copy
name_3 = name[:]
</code></pre><h3 id="26-list-arguments">2.6 List Arguments</h3><p>Tuples can be passed into functions as parameters using the <code>*</code> operator, and lists can also be passed as parameters to functions. At this time, the function will get a reference to the list, which means that if the function modifies the list, the original list will also be modified. The following example demonstrates this:</p><pre><code class="language-python"># Define a function to delete the first element of a list
def del_head(t):
  del t[0]

name = [&apos;Adam&apos;, &apos;is&apos;, &apos;very&apos;, &apos;cool&apos;]
del_head(name)
print(name)
</code></pre><p>Output:</p><pre><code>[&apos;is&apos;, &apos;very&apos;, &apos;cool&apos;]
</code></pre><p>Parameter <code>t</code> and the variable <code>name</code> refer to the same list, so when <code>t</code> changes, <code>name</code> also changes. This knowledge point is very important. When writing functions, be very careful about whether the operation will create a new list or make changes to the original list.</p><h3 id="27-mapping-and-list-comprehensions">2.7 Mapping and List Comprehensions</h3><p>If you want to operate on a list with a function, mapping and list comprehensions are good choices. The built-in function map provided by Python takes two parameters - a mapping function and an iterable object, and returns an iterable object. The following example demonstrates this:</p><pre><code class="language-python"># Return the square of the element
def square(n):
    return n*n

test_list = [1,2,4,5]
result = map(square, test_list)
print(result)
print(list(result))
</code></pre><p>Output:</p><pre><code>&lt;map object at 0x1101b9400&gt;
[1, 4, 16, 25]
</code></pre><p>You can also use list comprehensions to perform the same operation:</p><pre><code class="language-python">test_list = [1,2,4,5]
result = [i*i for i in test_list]
print(result)
</code></pre><p>Output:</p><pre><code>[1, 4, 16, 25]
</code></pre><h2 id="3-summary">3. Summary</h2><p>The above knowledge basically summarizes the common operations on lists. Here&apos;s a brief summary of the experience:</p><ul><li>Most list methods modify the list in place and return <code>None</code>, so it&apos;s important to choose the appropriate method and ensure the safety of variables.</li><li>There are multiple ways to achieve the same operation, and sometimes using the wrong method may not result in an error, but the result might be incorrect. Make sure to understand the differences before choosing the appropriate method.</li><li>Be cautious when using aliases for lists. It&apos;s not just lists, other data types can also have aliasing mechanisms.</li></ul><p>I hope these points have been helpful to you. Let&apos;s solidify our knowledge of lists with a LeetCode algorithm problem. Feel free to leave your answer in the comments! Next time, we&apos;ll talk about dictionaries (<code>Dict</code>).</p><p>Problem: Rotate Array</p><p>Given an array, rotate the array to the right by k steps, where k is a non-negative integer. Example:</p><pre><code>Input: nums = [1,2,3,4,5,6,7], k = 3
Output: [5,6,7,1,2,3,4]
Explanation:
Rotate 1 step to the right: [7,1,2,3,4,5,6]
Rotate 2 steps to the right: [6,7,1,2,3,4,5]
Rotate 3 steps to the right: [5,6,7,1,2,3,4]

Author: LeetCode
Link: https://leetcode.com/leetbook/read/top-interview-questions-easy/x2skh7/
Source: LeetCode
Copyright: All rights reserved.</code></pre>]]></content:encoded></item><item><title><![CDATA[Tips for Common Operations with Python Tuples]]></title><description><![CDATA[<h2 id="1-introduction">1 Introduction</h2><p>Python, as a popular programming language, has attracted a lot of attention in the fields of data science and artificial intelligence. Many people are learning it. However, on the road to excellence, we must not neglect the basics, such as common data structures, syntax specifications, and best practices</p>]]></description><link>http://localhost:2368/tips-for-common-operations-with-python-tuples/</link><guid isPermaLink="false">64862f444543c30001eef840</guid><category><![CDATA[Tech]]></category><category><![CDATA[Python]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sat, 07 Aug 2021 05:00:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1514428631868-a400b561ff44?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDE5fHxweXRob258ZW58MHx8fHwxNjg2NTE1NTMwfDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<h2 id="1-introduction">1 Introduction</h2><img src="https://images.unsplash.com/photo-1514428631868-a400b561ff44?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDE5fHxweXRob258ZW58MHx8fHwxNjg2NTE1NTMwfDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Tips for Common Operations with Python Tuples"><p>Python, as a popular programming language, has attracted a lot of attention in the fields of data science and artificial intelligence. Many people are learning it. However, on the road to excellence, we must not neglect the basics, such as common data structures, syntax specifications, and best practices for programming thinking. By mastering these most fundamental things, we can easily handle the work based on them.</p><p>Let&apos;s first review and summarize the commonly used operations in Python data structures: The common data structures in Python can be collectively referred to as containers. Sequences (such as lists and tuples), mappings (such as dictionaries), and sets are the three main types of containers. Flat sequences such as str, bytes, bytearray, memoryview, and array.array are not within the scope of this article.</p><p>Here, we will start with tuples.</p><h2 id="2-tuples-are-not-just-immutable-lists">2 Tuples are not just immutable lists</h2><h3 id="21-record-function-of-tuples">2.1 Record Function of Tuples</h3><p>One of the significant differences between a tuple and a list is that it cannot be modified, but it has another function <a href="https://book.douban.com/subject/27028517/?ref=localhost">as a record for which there are no field names</a>. As the latter is often ignored, let&apos;s first look at the role of tuples as records.</p><p>A tuple can be defined using parentheses. Each element in the tuple stores the data of a field in the record, plus the position of this field. It is precisely this positional information that gives the data meaning. In the example below, the tuple is used as a record:</p><pre><code class="language-python"># Latitude and longitude of Los Angeles International Airport, recorded in a tuple
lax_coordinates = (33.9425, -118.408056)

# Information for Tokyo: city name, year, population (in millions), population change (in percentage), and area (in square kilometers), recorded in a tuple
city, year, pop, chg, area = (&apos;Tokyo&apos;, 2003, 32450, 0.66, 8014)

# A list of tuples in the form (country_code, passport_number)
traveler_ids = [(&apos;USA&apos;, &apos;31195855&apos;), (&apos;BRA&apos;, &apos;CE342567&apos;),(&apos;ESP&apos;, &apos;XDA205856&apos;)]

# During iteration, the passport variable is bound to each tuple. The % format operator can be matched to the corresponding tuple element.
for passport in sorted(traveler_ids):
  print(&apos;%s/%s&apos; % passport)
</code></pre><p>The output is:</p><pre><code>BRA/CE342567
ESP/XDA205856
USA/31195855
</code></pre><h3 id="22-tuple-unpacking">2.2 Tuple Unpacking</h3><p>The operation in the above for loop extracts the elements in the tuple, also known as tuple unpacking. Parallel assignment is an excellent application of unpacking tuples, as shown in the example below:</p><pre><code class="language-python"># Latitude and longitude of Los Angeles International Airport, recorded in a tuple
lax_coordinates = (33.9425, -118.408056)
# Unpack tuple and assign each element in the tuple to the corresponding variable
latitude, longitude = lax_coordinates
</code></pre><p>Another classic and elegant application is to swap the values of variables:</p><pre><code class="language-python">a, b = b, a
</code></pre><h3 id="23-tuples-as-function-parameters">2.3 Tuples as Function Parameters</h3><p>Use the <code>*</code> operator to unpack an iterable object as a function parameter. For example, Python&apos;s built-in function divmod takes two numeric arguments and returns the quotient and remainder. The following example uses <code>*</code> to pass the tuple to the function.</p><pre><code class="language-python">t = (20, 8)
quotient, remainder = divmod(*t)
print(quotient, remainder)
</code></pre><p>The output is:</p><pre><code>2 4
</code></pre><h3 id="24-tuples-as-function-return-values">2.4 Tuples as Function Return Values</h3><p>Some functions have multiple return values, and when they are assigned to a variable, the variable type is a tuple:</p><pre><code class="language-python">import numpy as np
arr = np.random.randint(10, size=8)

def count_sum(arr):
   count = len(arr)
   sum = arr.sum()
   return count, sum

result = count_sum(arr)
print(result)
</code></pre><p>The output is:</p><pre><code>(8, 40)
</code></pre><h3 id="25-zip-function">2.5 zip Function</h3><p>Zip is a built-in function in Python that can take two or more sequences and form a list of tuples. In Python 3, it returns an iterator, as shown below:</p><pre><code class="language-python">list_a = [1,2,3]
list_b = [&apos;a&apos;,&apos;b&apos;,&apos;c&apos;]

for i in zip(list_a, list_b):
    print(i)
</code></pre><p>The output is:</p><pre><code>(1, &apos;a&apos;)
(2, &apos;b&apos;)
(3, &apos;c&apos;)
</code></pre><h3 id="26-other-common-operations">2.6 Other Common Operations</h3><p>Tuples also support some common operations, such as for the tuple <code>a = (1, &apos;y&apos;, 5, 5, &apos;x&apos;)</code>:</p><ul><li>Indexing, such as <code>a.index(&apos;x&apos;)</code></li><li>Slicing, such as <code>a[1:4]</code></li><li>Counting, such as <code>a.count(5)</code></li><li>Sorting, such as <code>a.sort()</code></li><li>Merging tuples, such as <code>c = a + a</code></li></ul><h2 id="3-summary">3 Summary</h2><p>The above content not only covers the basic operations of tuples but also combines other functions, operators, and so on that are often used in practical work. When reviewing this knowledge, I mainly referred to two classic Python programming books: &quot;Fluent Python&quot; and &quot;Think Python: How to Think Like a Computer Scientist,&quot; and interested friends can read them in-depth!</p><p>I hope this article is helpful to you, and next time, I will summarize the tips for using Python lists.</p>]]></content:encoded></item><item><title><![CDATA[Introduction to Google Analytics]]></title><description><![CDATA[<h2 id="1-introduction">1. Introduction</h2><p>Many products and strategic decisions on the internet today are driven by data. For example, at BulletTech, when operating WeChat official accounts, we monitor important indicators such as traffic sources, replication, and follow-up after reading through backend data for each article. This data can help us analyze reader</p>]]></description><link>http://localhost:2368/introduction-to-google-analytics/</link><guid isPermaLink="false">64862e244543c30001eef822</guid><category><![CDATA[Tech]]></category><category><![CDATA[Analytics]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sat, 31 Jul 2021 05:00:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1526628953301-3e589a6a8b74?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDV8fGFuYWx5dGljc3xlbnwwfHx8fDE2ODY1MTUzMzN8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<h2 id="1-introduction">1. Introduction</h2><img src="https://images.unsplash.com/photo-1526628953301-3e589a6a8b74?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDV8fGFuYWx5dGljc3xlbnwwfHx8fDE2ODY1MTUzMzN8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Introduction to Google Analytics"><p>Many products and strategic decisions on the internet today are driven by data. For example, at BulletTech, when operating WeChat official accounts, we monitor important indicators such as traffic sources, replication, and follow-up after reading through backend data for each article. This data can help us analyze reader preferences, traffic channels, and make flexible adjustments to article themes and promotional strategies. For platforms that already have a good data analysis infrastructure, ready-made solutions can save decision makers a lot of time. But if you have built a product from scratch, how do you construct the infrastructure and strategy for data analysis? This article will take BulletTech&apos;s blog as an example to introduce how to use Google Analytics (Google Analytics) to analyze website performance.</p><h2 id="2-the-role-of-google-analytics">2. The Role of Google Analytics</h2><p>Google Analytics is a free tool released by Google for website and mobile app analysis. After Google Analytics is configured on a website, it can capture user behavior data on the website to help optimize it. Google Analytics plays an important role in the following areas of analysis:</p><ul><li>Marketing: Google Analytics can clearly show the behavior and conversion rates of users from each channel on the website, helping to optimize inferior channels.</li><li>Search Engine Optimization (SEO): Google Analytics has multiple dimensions for traffic acquisition, allowing you to see which content helps get more clicks.</li><li>Site content: Information such as which pages users stay on longest, which pages are viewed the most, which pages have the highest conversion rates, site performance, etc. can be seen in Google Analytics and are key information for optimizing content.</li></ul><h2 id="3-tips-for-using-google-analytics">3. Tips for Using Google Analytics</h2><p>Firstly, you need to configure Google Analytics for your website. Google provides a detailed <a href="https://support.google.com/analytics/answer/1008015?hl=en&amp;ref=localhost">tutorial</a>, so it will not be repeated here. With a few simple steps, you can deploy a tracking ID or tracking code on your website and Google Analytics can help collect data. This data is a precious resource for analysis and decision making in the future.</p><p>Google Analytics provides many dimensions of data for users to build their own analysis reports. The Google Analytics sidebar is classified by data type:</p><ul><li>Home: Important indicators preset by Google.</li><li>Custom: User-defined reports.</li><li>Real-time: Real-time data on the site.</li><li>Audience: User profile data.</li><li>Acquisition: Traffic profile data.</li><li>Behavior: User behavior data on the site.</li><li>Conversion: Conversion data for goals and e-commerce.</li></ul><p>Basically, in each type, there is an overview and a detailed presentation of specific data details in subcategories.</p><h3 id="31-home">3.1 Home</h3><p>Home contains important indicators preset by Google for a quick overview of the site&apos;s overall performance, such as user volume, performance of various traffic sources, user geographic distribution, browsing time, most clicked pages, device type, etc. Google also provides an analysis intelligent module that can adaptively summarize insights.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/2021-7-31/1627739241720-Home.png" class="kg-image" alt="Introduction to Google Analytics" loading="lazy"><figcaption>Home</figcaption></figure><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/2021-8-1/1627790805820-%E6%B4%9E%E8%A7%81.png" class="kg-image" alt="Introduction to Google Analytics" loading="lazy"><figcaption>Google Analytics Intelligent Analysis</figcaption></figure><h3 id="32-audience">3.2 Audience</h3><p>This module is mainly used to describe user profiles, such as new and old users, geographic distribution, session performance, device type, operating system type, etc. This information helps you understand the overall situation of site users. There is even finer-grained information for viewing and analysis in the side tags.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/2021-7-31/1627742550450-%E4%BA%BA%E7%BE%A4.png" class="kg-image" alt="Introduction to Google Analytics" loading="lazy"><figcaption>Audience Profile</figcaption></figure><h3 id="33-acquisition">3.3 Acquisition</h3><p>This section mainly introduces traffic sources such as orGoogle Analyticsnic traffic, social media drainage, direct clicks to enter, and referral traffic. It also includes traffic performance for each channel. This information helps to measure the traffic conversion effect of each channel and formulate promotion and traffic acquisition strategies. For example, BulletTech&apos;s blog is deployed on GitHub, and the search engine optimization of GitHub Pages is not favorable, so it does not have an advantage in natural traffic acquisition. The main source of traffic is clicking the original article link on various social media platforms to jump to the webpage.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/2021-8-1/1627781320848-%E8%8E%B7%E5%AE%A2.png" class="kg-image" alt="Introduction to Google Analytics" loading="lazy"><figcaption>Acquisition</figcaption></figure><h3 id="34-user-behavior">3.4 User Behavior</h3><p>The click-through rate of users on each page, the time they spend on each page, the page&apos;s incoming and outgoing links, bounce rate, and other information can be viewed in this module. These pieces of information can help you analyze user preferences for content, allowing for content to be more targeted.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/2021-8-1/1627782229120-%E8%A1%8C%E4%B8%BA.png" class="kg-image" alt="Introduction to Google Analytics" loading="lazy"><figcaption>User Behavior</figcaption></figure><h3 id="35-custom-reports">3.5 Custom Reports</h3><p>The above reports provide insight into different dimensions, and Google Analytics also provides options to build your own data indicator system more flexibly. By customizing reports, you can select various basic data and put them together into a special report suitable for your project. Google Analytics also offers a community to <a href="https://analytics.google.com/analytics/GoogleAnalyticsllery/?ref=localhost">share data dashboards created by others</a>, making it easier to refer to excellent report templates shared by others.</p><h2 id="conclusion">Conclusion</h2><p>Google Analytics is like a beacon of light in the dark of the website, helping site builders better understand users and support decision-making. Google also provides a <a href="https://analytics.google.com/analytics/academy/course/6?ref=localhost">series of courses</a> and <a href="https://skillshop.exceedlms.com/student/path/2938-google-analytics-individual-qualification?ref=localhost">analytics qualifications certification</a> to help you learn Google Analytics more systematically. Google Analytics also supports <a href="https://developers.google.com/analytics/solutions/mobile?ref=localhost">analyzing mobile applications</a>, making it a powerful multi-faceted tool!</p><p>I hope this share is helpful to you! Welcome to discuss in the comments!</p>]]></content:encoded></item></channel></rss>