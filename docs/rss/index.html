<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:media="http://search.yahoo.com/mrss/"><channel><title><![CDATA[Spacecraft]]></title><description><![CDATA[Healthy food for thoughts about this beautiful life!]]></description><link>https://realvincentyuan.github.io/Spacecraft/</link><image><url>https://realvincentyuan.github.io/Spacecraft/favicon.png</url><title>Spacecraft</title><link>https://realvincentyuan.github.io/Spacecraft/</link></image><generator>Ghost 5.49</generator><lastBuildDate>Wed, 12 Jul 2023 01:38:38 GMT</lastBuildDate><atom:link href="https://realvincentyuan.github.io/Spacecraft/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[Summary of Machine Learning Reference Resources (Continuously Updated)]]></title><description><![CDATA[<h2 id="1-overview">1 Overview</h2><p>The purpose of this article is to summarize the machine learning reference materials that I usually use, facilitate my own review and update at any time, and also share with friends who need it. This article will be updated from time to time to ensure the relevance of</p>]]></description><link>https://realvincentyuan.github.io/Spacecraft/summary-of-machine-learning-learning-resources-continuously-updated/</link><guid isPermaLink="false">64a8bf074e1c2f000108efd5</guid><category><![CDATA[Tech]]></category><category><![CDATA[AI]]></category><category><![CDATA[Python]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sun, 18 Dec 2022 06:00:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1558901357-ca41e027e43a?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDE4fHxib29rfGVufDB8fHx8MTY4ODI2Mzk1M3ww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<h2 id="1-overview">1 Overview</h2><img src="https://images.unsplash.com/photo-1558901357-ca41e027e43a?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDE4fHxib29rfGVufDB8fHx8MTY4ODI2Mzk1M3ww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Summary of Machine Learning Reference Resources (Continuously Updated)"><p>The purpose of this article is to summarize the machine learning reference materials that I usually use, facilitate my own review and update at any time, and also share with friends who need it. This article will be updated from time to time to ensure the relevance of the contents.</p><h2 id="2-online-courses">2 Online Courses</h2><ul><li><a href="https://www.bilibili.com/video/BV1pp4y1t7Na?spm_id_from=333.337.search-card.all.click&amp;ref=localhost">Standford CS 229: Machine Learning - Bilibili</a></li><li><a href="https://www.youtube.com/watch?v=P127jhj-8-Y&amp;list=PLoROMvodv4rNiJRchCzutFw5ItR_Z27CM&amp;ab_channel=StanfordOnline&amp;ref=localhost">Stanford Seminar CS25: Transformers United - YouTube</a></li><li><a href="https://space.bilibili.com/1567748478/channel/series?ref=localhost">&#x674E;&#x6C90;&#x5B66;AI - Bilibili</a></li><li><a href="https://dbourke.link/ZTMTFcourse?ref=localhost">TensorFlow Developer Certificate Course - Zero to Mastery</a></li><li><a href="https://www.udacity.com/course/intro-to-tensorflow-for-deep-learning--ud187?ref=localhost">Intro to TensorFlow for Deep Learning - Udacity</a></li><li><a href="https://developers.google.com/machine-learning/crash-course?ref=localhost">Machine Learning Crash Course - Google</a></li><li><a href="https://microsoft.github.io/ML-For-Beginners/?ref=localhost#/">Machine Learning for Beginners - Microsoft</a></li><li><a href="https://microsoft.github.io/Data-Science-For-Beginners/?ref=localhost#/">Data Science for Beginners - Microsoft</a></li><li><a href="https://www.kaggle.com/learn?ref=localhost">Kaggle courses</a></li></ul><h2 id="3-technical-blogs-e-books">3 Technical Blogs &amp; E-Books</h2><h3 id="31-technical-blogs">3.1 Technical Blogs</h3><ul><li><a href="https://medium.com/kaggle-blog?ref=localhost">Kaggle Winner&apos;s Blog</a></li><li><a href="http://jalammar.github.io/?ref=localhost">Visualizing machine learning one concept at a time - Jay Alammar</a></li><li><a href="https://hanxiao.io/?ref=localhost">Han Xiao tech blog</a></li><li><a href="https://blog.google/technology/ai/?ref=localhost">Google AI</a></li><li><a href="https://openai.com/?ref=localhost">Open AI</a></li><li><a href="https://www.unofficialgoogledatascience.com/?ref=localhost">The Unofficial Google Data Science Blog</a></li><li><a href="http://karpathy.github.io/?ref=localhost">Andrej Karpathy blog</a></li><li><a href="http://blog.echen.me/?ref=localhost">Surge AI blog</a></li><li><a href="https://paperswithcode.com/?ref=localhost">Paper with Code</a></li><li><a href="http://blog.datadive.net/?ref=localhost">Diving into data</a></li><li><a href="https://blog.cloudera.com/?ref=localhost">Cloudera Blog</a></li><li><a href="http://drivendata.github.io/cookiecutter-data-science/?ref=localhost">Cookiecutter Data Science</a></li><li><a href="https://huggingface.co/blog/zh?ref=localhost">Hugging Face Chinese Blog</a></li></ul><h3 id="32-e-books">3.2 E-Books</h3><ul><li><a href="https://dev.mrdbourke.com/tensorflow-deep-learning/?ref=localhost">TensorFlow Developer Certificate Learning E-book</a></li><li><a href="https://tf.wiki/?ref=localhost">&#x7B80;&#x5355;&#x7C97;&#x66B4; TensorFlow 2 | A Concise Handbook of TensorFlow 2</a></li><li><a href="https://lyhue1991.github.io/eat_tensorflow2_in_30_days/chinese/?ref=localhost">30&#x5929;&#x5403;&#x6389;&#x90A3;&#x53EA;TensorFlow2</a></li><li><a href="https://huyenchip.com/ml-interviews-book/?ref=localhost">Machine Learning Interviews Book</a></li><li><a href="https://zh-v2.d2l.ai/?ref=localhost">&#x52A8;&#x624B;&#x5B66;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60; - Amazon</a></li><li><a href="https://huggingface.co/course/chapter1/1?ref=localhost">HuggingFace Course</a></li><li><a href="https://otexts.com/fpp3/index.html?ref=localhost">Forecasting: Principles and Practice - 3rd Edition</a></li><li><a href="https://developers.google.com/machine-learning/guides/rules-of-ml?ref=localhost#terminology">Rules of Machine Learning</a></li><li><a href="https://ml-cheatsheet.readthedocs.io/en/latest/index.html?ref=localhost">Machine Learning Glossary</a></li></ul><h2 id="4-github-resources">4 GitHub Resources</h2><ul><li><a href="https://github.com/microsoft/Data-Science-For-Beginners?ref=localhost">Data-Science-For-Beginners - Microsoft</a></li><li><a href="https://github.com/microsoft/ML-For-Beginners?ref=localhost">ML-For-Beginners - Microsoft</a></li><li><a href="https://github.com/ageron/handson-ml2?ref=localhost">Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow</a></li><li><a href="https://github.com/lmoroney/dlaicourse?ref=localhost">TensorFlow In Practice</a></li><li><a href="https://github.com/tensorflow/examples?ref=localhost">TensorFlow Examples</a></li><li><a href="https://github.com/google-research/tuning_playbook?ref=localhost">Deep Learning Tuning Playbook</a></li></ul><h2 id="5-notion-notes">5 Notion Notes</h2><ul><li><a href="https://www.notion.so/Course-TensorFlow-in-Practice-on-Coursera-Notes-5f4f8915fe3342e2a69f75ef1986ba3b?ref=localhost">TensorFlow in Practice on Coursera Notes</a></li><li><a href="https://www.notion.so/Course-MIT-Introduction-to-Deep-Learning-Notes-0e48ecc9ed7342b7b448956bed9e0e75?ref=localhost">MIT Introduction to Deep Learning Notes</a></li></ul><h2 id="6-competition-experience">6 Competition Experience</h2><ul><li><a href="https://zhuanlan.zhihu.com/p/472915303?ref=localhost">2021 Kaggle All Event TOP Solution Summary</a></li></ul><h3 id="61-exploratory-data-analysis">6.1 Exploratory Data Analysis</h3><ul><li><a href="https://www.kaggle.com/code/kashnitsky/topic-1-exploratory-data-analysis-with-pandas/notebook?ref=localhost">Exploratory Data Analysis with Pandas</a></li><li><a href="https://www.kaggle.com/code/pmarcelino/comprehensive-data-exploration-with-python?ref=localhost">Comprehensive data exploration with Python</a></li></ul><h3 id="62-feature-engineering">6.2 Feature Engineering</h3><ul><li><a href="https://www.kaggle.com/competitions/ieee-fraud-detection/discussion/108575?ref=localhost">Feature Engineering Techniques</a></li><li><a href="https://www.kaggle.com/code/kyakovlev/ieee-fe-for-local-test/notebook?ref=localhost">IEEE - FE for Local test</a></li></ul><h3 id="63-tabular-data-modeling">6.3 Tabular Data Modeling</h3><ul><li><a href="https://neptune.ai/blog/tabular-data-binary-classification-tips-and-tricks-from-5-kaggle-competitions?ref=localhost">Tabular Data Binary Classification: All Tips and Tricks from 5 Kaggle Competitions</a></li><li><a href="https://www.kaggle.com/code/vbmokin/data-science-for-tabular-data-advanced-techniques/notebook?ref=localhost">Data Science for tabular data: Advanced Techniques</a></li><li><a href="https://www.kaggle.com/competitions/amex-default-prediction/discussion/335892?ref=localhost">Tabular Classification - Tips and Tricks</a></li><li><a href="https://www.kaggle.com/code/arthurtok/feature-ranking-rfe-random-forest-linear-models?ref=localhost">Feature Ranking RFE, Random Forest, linear models</a></li></ul><h3 id="64-time-series-modeling">6.4 Time Series Modeling</h3><ul><li><a href="https://www.kaggle.com/code/kashnitsky/topic-9-part-1-time-series-analysis-in-python?ref=localhost">Time Series Analysis in Python</a></li><li><a href="https://www.kaggle.com/code/dimitreoliveira/deep-learning-for-time-series-forecasting/notebook?ref=localhost">Deep Learning for Time Series Forecasting</a></li><li><a href="https://www.kaggle.com/code/dimitriosroussis/electricity-price-forecasting-with-dnns-eda?ref=localhost">Electricity price forecasting with DNNs (+ EDA)</a></li></ul><h2 id="7-summary">7 Summary</h2><p>This article will be continuously updated, and comments are welcome to add resources.</p>]]></content:encoded></item><item><title><![CDATA[Free Experiment Platform - Amazon SageMaker Studio Lab]]></title><description><![CDATA[<h2 id="1-sagemaker-studio-lab">1 SageMaker Studio Lab</h2><p>I have always been a loyal user of Google Colab, and its free GPUs are very useful computing resources for data science researchers. However, the basic free version of Colab can only use one runtime at a time and must have scientific internet access to access</p>]]></description><link>https://realvincentyuan.github.io/Spacecraft/free-experiment-platform-amazon-sagemaker-studio-lab/</link><guid isPermaLink="false">64a8bf074e1c2f000108efd4</guid><category><![CDATA[Tech]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sat, 28 May 2022 05:00:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1498050108023-c5249f4df085?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDN8fGNvZGV8ZW58MHx8fHwxNjg4MjYzNzcyfDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<h2 id="1-sagemaker-studio-lab">1 SageMaker Studio Lab</h2><img src="https://images.unsplash.com/photo-1498050108023-c5249f4df085?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDN8fGNvZGV8ZW58MHx8fHwxNjg4MjYzNzcyfDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Free Experiment Platform - Amazon SageMaker Studio Lab"><p>I have always been a loyal user of Google Colab, and its free GPUs are very useful computing resources for data science researchers. However, the basic free version of Colab can only use one runtime at a time and must have scientific internet access to access the product. Recently, Amazon launched the <a href="https://studiolab.sagemaker.aws/?ref=localhost">SageMaker Studio Lab</a>, which can be seen as a similar product to Google Colab. Amazon also generously provides free computing power (with CPU and GPU options). ==After registering an account, experiments can be conducted anytime on the web without needing scientific internet access! ==</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/1_V/SageMaker_studio_lab.jpg" class="kg-image" alt="Free Experiment Platform - Amazon SageMaker Studio Lab" loading="lazy"><figcaption>Amazon SageMaker Studio Lab</figcaption></figure><p>Note: I occasionally encountered a prompt saying &quot;there are too many users currently using the CPU and GPU projects concurrently, and they cannot be launched&quot; during the use of CPU and GPU projects, and the resources of the GPU are more scarce compared with Google Colab. If this situation occurs, you can wait a few minutes. If it still cannot be launched, you can only use another environment for experiments. I have never encountered this situation in Google Colab, and I am not sure if it will be improved in the future.</p><p>After entering the project, the software interface is very similar to the native JupyterLab, and if you have similar experience, you can start using it immediately. At the same time, this also means that users can run multiple code files at the same time, which is an advantage of Amazon SageMaker Studio Lab compared to Google Colab.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/1_V/Jupyter.png" class="kg-image" alt="Free Experiment Platform - Amazon SageMaker Studio Lab" loading="lazy"><figcaption>Jupyter user interface</figcaption></figure><p>Files will still be stored in the system after the project is closed, which makes it convenient to continue using them next time. Overall, the experience of Amazon SageMaker Studio Lab is basically the same as the native JupyterLab.</p><h2 id="2-other-related-learning-resources">2 Other related learning resources</h2><p>Amazon SageMaker Studio Lab displays some reference projects on the project homepage, such as <code>Dive into Deep Learning (D2L)</code>, <code>Hugging Face</code>, etc. These are all excellent learning resources. You can click to copy the project to your own file system and practice.</p><p>Among them, <code>Dive into Deep Learning (D2L)</code> is led by Amazon&apos;s <code>Sr. Principal Scientist Li Mu</code> (also known as Mu Li), and Mu Li offers free courses on deep learning on multiple platforms:</p><ul><li>The e-book &quot;Dive into Deep Learning&quot;: <a href="https://d2l.ai/?ref=localhost">https://d2l.ai/</a></li><li>Bilibili @Learning AI with Li Mu: <a href="https://space.bilibili.com/1567748478/channel/seriesdetail?sid=358497&amp;ref=localhost">https://space.bilibili.com/1567748478/channel/seriesdetail?sid=358497</a></li></ul><p>If you are interested, you can go to the corresponding platform to learn and practice! I hope this sharing is helpful to you, and I welcome you to discuss it in the comments section!</p>]]></content:encoded></item><item><title><![CDATA[Neo4J Graph Database Anti-Fraud Analysis in Practice (IV) - Risk Scoring]]></title><description><![CDATA[<h2 id="1-preface">1 Preface</h2><p>In the Neo4J graph database anti-fraud series, we have identified risky users. This article will explain how to score the risk of each customer. If you need to review the previous articles, you can directly jump to the links:</p><ul><li><a href="https://realvincentyuan.github.io/Spacecraft/introduction-to-graph-databases">Introduction to Graph Database</a></li><li><a href="https://realvincentyuan.github.io/Spacecraft/neo4j-graph-database-anti-fraud-analysis-practice-part-1-building-analysis-environment">Neo4j Graph Database Anti-Fraud Analysis</a></li></ul>]]></description><link>https://realvincentyuan.github.io/Spacecraft/neo4j-graph-database-anti-fraud-analysis-practice-iii-identifying-criminal-groups/</link><guid isPermaLink="false">64a8bf074e1c2f000108efcc</guid><category><![CDATA[Tech]]></category><category><![CDATA[Knowledge Graph]]></category><category><![CDATA[Python]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sat, 09 Apr 2022 05:00:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1590859808308-3d2d9c515b1a?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDN8fE5ldHxlbnwwfHx8fDE2ODgyNjEwNTF8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<h2 id="1-preface">1 Preface</h2><img src="https://images.unsplash.com/photo-1590859808308-3d2d9c515b1a?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDN8fE5ldHxlbnwwfHx8fDE2ODgyNjEwNTF8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Neo4J Graph Database Anti-Fraud Analysis in Practice (IV) - Risk Scoring"><p>In the Neo4J graph database anti-fraud series, we have identified risky users. This article will explain how to score the risk of each customer. If you need to review the previous articles, you can directly jump to the links:</p><ul><li><a href="https://realvincentyuan.github.io/Spacecraft/introduction-to-graph-databases">Introduction to Graph Database</a></li><li><a href="https://realvincentyuan.github.io/Spacecraft/neo4j-graph-database-anti-fraud-analysis-practice-part-1-building-analysis-environment">Neo4j Graph Database Anti-Fraud Analysis In Practice (I) - Build Analysis Environment</a></li><li><a href="https://realvincentyuan.github.io/Spacecraft/neo4j-graph-database-anti-fraud-analysis-in-practice-part-2-prepare-data">Neo4j Graph Database Anti-Fraud Analysis In Practice (II) - Data Preparation</a></li><li><a href="https://realvincentyuan.github.io/Spacecraft/neo4j-graph-database-anti-fraud-analysis-practice-iii-identifying-criminal-groups">Neo4j Graph Database Anti-Fraud Analysis In Practice (III) - Identify Criminal Organizations</a></li></ul><h2 id="2-finding-similar-nodes">2 Finding Similar Nodes</h2><p>Last time, we used the <a href="https://neo4j.com/docs/graph-data-science/current/algorithms/wcc/?ref=localhost">Weakly Connected Components</a> algorithm to cluster the data. Next, we can look for similar customers in each cluster.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/1_V/cluster_1.png" class="kg-image" alt="Neo4J Graph Database Anti-Fraud Analysis in Practice (IV) - Risk Scoring" loading="lazy"><figcaption>WCC clustering results</figcaption></figure><p>This step uses node similarity (<a href="https://neo4j.com/docs/graph-data-science/current/algorithms/node-similarity/?ref=localhost#algorithms-node-similarity">Jaccard coefficient</a>) to judge. The node similarity algorithm requires two types of nodes in the graph structure, so we create the <code>Similarity</code> graph, which contains two types of nodes: <code>Client</code> and <code>Entity</code> information nodes, and their corresponding relationships.</p><pre><code class="language-sql">CALL gds.graph.project.cypher(&apos;Similarity&apos;,
&apos;MATCH(c:Client)
    WHERE exists(c.firstPartyFraudGroup)
    RETURN id(c) AS id,labels(c) AS labels
UNION
MATCH(n)
    WHERE n:Email OR n:Phone OR n:SSN
    RETURN id(n) AS id,labels(n) AS labels&apos;,
&apos;MATCH(c:Client)
-[:HAS_EMAIL|:HAS_PHONE|:HAS_SSN]-&gt;(ids)
WHERE exists(c.firstPartyFraudGroup)
RETURN id(c) AS source,id(ids) AS target&apos;)
YIELD graphName,nodeCount,relationshipCount;
</code></pre><p>After creating the graph, we can run the node similarity algorithm (note: the algorithm supports weighting, see the documentation for details&#xFF09;&#xFF1A;</p><pre><code class="language-sql">CALL gds.nodeSimilarity.stream(&apos;Similarity&apos;,{topK:15})
YIELD node1,node2,similarity
RETURN gds.util.asNode(node1).id AS client1,
    gds.util.asNode(node2).id AS client2,similarity
ORDER BY similarity;
</code></pre><p>Use the <code>Mutate</code> mode to write the results to the graph in memory, creating a new relationship <code>SIMILAR_TO</code>. At this point, the similarity between the pairs of similar nodes can be measured using the jaccardScore:</p><pre><code class="language-sql">CALL gds.nodeSimilarity.mutate(&apos;Similarity&apos;,{topK:15,
  mutateProperty:&apos;jaccardScore&apos;, mutateRelationshipType:&apos;SIMILAR_TO&apos;});

-- Write the results from the in-memory graph to the database
CALL gds.graph.writeRelationship(&apos;Similarity&apos;,&apos;SIMILAR_TO&apos;,&apos;jaccardScore&apos;);
</code></pre><h2 id="3-creating-risk-scores">3 Creating Risk Scores</h2><p>Next, we use the <a href="https://neo4j.com/docs/graph-data-science/current/algorithms/degree-centrality/?ref=localhost">Node Centrality algorithm</a> combined with the similarity indicator generated above to generate a <code>firstPartyFraudScore</code>. The higher the <code>firstPartyFraudScore</code>, the more similar the entity information of the client with many customers in a cluster, indicating that it is more dangerous.</p><pre><code class="language-sql">CALL gds.degree.write(&apos;Similarity&apos;,{nodeLabels:[&apos;Client&apos;],
    relationshipTypes:[&apos;SIMILAR_TO&apos;],
    relationshipWeightProperty:&apos;jaccardScore&apos;,
    writeProperty:&apos;firstPartyFraudScore&apos;});
</code></pre><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/1_V/Score.png" class="kg-image" alt="Neo4J Graph Database Anti-Fraud Analysis in Practice (IV) - Risk Scoring" loading="lazy"><figcaption>Risk score distribution</figcaption></figure><p>Finally, we select the 80th percentile as the threshold to mark dangerous clients. In actual applications, you can also use <code>firstPartyFraudScore</code> as a separate feature and integrate it into an anti-fraud strategy or model.</p><pre><code class="language-sql">MATCH(c:Client)
WHERE exists(c.firstPartyFraudScore)
WITH percentileCont(c.firstPartyFraudScore, 0.8)
    AS firstPartyFraudThreshold
MATCH(c:Client)
WHERE c.firstPartyFraudScore&gt;firstPartyFraudThreshold
SET c:FirstPartyFraudster;
</code></pre><h2 id="4-summary">4 Summary</h2><p>The Neo4J Graph Database Anti-Fraud Analysis Practical Series has come to an end. Through this series of articles, we have learned and consolidated the following knowledge points:</p><ul><li>Basics of graph structure</li><li>Neo4J graph database query language Cypher common commands</li><li>Common algorithms in anti-fraud applications</li></ul>]]></content:encoded></item><item><title><![CDATA[Neo4J Graph Database Anti-Fraud Analysis in Practice (III) - Identifying Criminal Groups]]></title><description><![CDATA[<h2 id="1-introduction">1 Introduction</h2><p>In the <a href="https://realvincentyuan.github.io/Spacecraft/neo4j-graph-database-anti-fraud-analysis-in-practice-part-2-prepare-data">Neo4J Graph Database Anti-Fraud Analysis Practice (II) - Preparing Data</a> section, I introduced how to import data into the Neo4J analysis platform and performed some simple descriptive analysis of customer and transaction information. Next, we need to look for fraudsters selectively, and their identity information (such</p>]]></description><link>https://realvincentyuan.github.io/Spacecraft/neo4j-graph-database-anti-fraud-analysis-practice-iii-identifying-criminal-groups-2/</link><guid isPermaLink="false">64a8bf074e1c2f000108efcd</guid><category><![CDATA[Tech]]></category><category><![CDATA[Knowledge Graph]]></category><category><![CDATA[Python]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sun, 06 Mar 2022 06:00:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1590859808308-3d2d9c515b1a?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDN8fE5ldHxlbnwwfHx8fDE2ODgyNjEwNTF8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<h2 id="1-introduction">1 Introduction</h2><img src="https://images.unsplash.com/photo-1590859808308-3d2d9c515b1a?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDN8fE5ldHxlbnwwfHx8fDE2ODgyNjEwNTF8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Neo4J Graph Database Anti-Fraud Analysis in Practice (III) - Identifying Criminal Groups"><p>In the <a href="https://realvincentyuan.github.io/Spacecraft/neo4j-graph-database-anti-fraud-analysis-in-practice-part-2-prepare-data">Neo4J Graph Database Anti-Fraud Analysis Practice (II) - Preparing Data</a> section, I introduced how to import data into the Neo4J analysis platform and performed some simple descriptive analysis of customer and transaction information. Next, we need to look for fraudsters selectively, and their identity information (such as phone numbers, ID numbers, etc.) is intertwined with many other accounts, and therefore clues can be found through these shared information.</p><h2 id="2-shared-identity-information">2 Shared Identity Information</h2><p>In the previous section, the relationship between clients and entities has been defined, such as a client having an email, phone number, SSN, etc. If multiple clients use the same information, these contacts can ensure that they are connected together, which greatly helps us deconstruct complex relationships. However, in order to run specific graph algorithms, these relationships need to be processed, because different graph structures are suitable for different graph algorithms, some algorithms are suitable for <code>homogeneous</code> graphs, that is, all node types in the graph are the same, only one type of relationship. Some algorithms are suitable for <code>heterogeneous</code> graphs, which contain multiple types of nodes and relationships.</p><p>The example provided by Neo4J uses the <a href="https://neo4j.com/docs/graph-data-science/current/algorithms/wcc/?ref=localhost">Weakly Connected Components</a> algorithm to find connected nodes in an undirected graph, which is suitable for a homogeneous graph, so a new relationship - <code>SHARED_IDENTIFIERS</code> needs to be created to calculate the number of shared entity information among each client, such as if the email, phone number, and SSN of clients A and B are the same, then the attribute count of SHARED_IDENTIFIERS is 3.</p><pre><code class="language-sql">// Create the SHARED_IDENTIFIERS relationship
MATCH (c1:Client)-[:HAS_EMAIL|:HAS_PHONE|:HAS_SSN]-&gt;(info)
&lt;-[:HAS_EMAIL|:HAS_PHONE|:HAS_SSN]-(c2:Client)
WHERE c1.id&lt;&gt;c2.id
WITH c1, c2, count(*) as cnt
MERGE (c1) - [:SHARED_IDENTIFIERS {count: cnt}] - (c2);
</code></pre><p>The <code>WITH</code> keyword can chain the query statements together, making it easy for variables in the previous step to be reused in the next step. The <code>MERGE</code> keyword is very versatile. In summary, it can make a pattern exist in the graph. If the pattern does not exist, it creates the pattern. It is used here to create a relationship. Please note that the example has a small amount of data and only has 300,000 nodes. If the number of nodes is large, it is recommended to use the <a href="https://neo4j.com/labs/apoc/4.2/overview/apoc.periodic/apoc.periodic.iterate/?ref=localhost">APOC</a> method provided by Neo4J to run in batches.</p><h2 id="3-create-the-graph">3 Create the Graph</h2><p>Before running any algorithms, you must first create the graph. You can use the <code>SHARED_IDENTIFIERS</code> relationship created earlier to build the graph and map it to memory. Therefore, Neo4J recommends estimating memory before building the graph or running the algorithm to ensure that the computing resources can meet the requirements:</p><pre><code class="language-sql">CALL gds.graph.create.cypher.estimate(
&apos;MATCH (c:Client) RETURN id(c) AS id&apos;,
&apos;MATCH (c1:Client)-[r:SHARED_IDENTIFIERS]-(c2:Client)
WHERE c1.id&lt;&gt;c2.id
RETURN id(c1) AS source,id(c2) AS target,r.count AS weight&apos;)
YIELD requiredMemory,nodeCount,relationshipCount;
</code></pre><p>The output is:</p><!--kg-card-begin: html--><table>
<thead>
<tr>
<th>requiredMemory</th>
<th>nodeCount</th>
<th>relationshipCount</th>
</tr>
</thead>
<tbody>
<tr>
<td>&quot;8804 KiB&quot;</td>
<td>2433</td>
<td>1517</td>
</tr>
</tbody>
</table><!--kg-card-end: html--><p>After ensuring that sufficient memory is available, you can formally create the graph:</p><pre><code class="language-sql">CALL gds.graph.create(&apos;WCC&apos;, &apos;Client&apos;,
	{
    	SHARED_IDENTIFIERS:{
        	type: &apos;SHARED_IDENTIFIERS&apos;,
        	properties: {
            	count: {
                	property: &apos;count&apos;
                }
            }
        }
	}
) YIELD graphName,nodeCount,relationshipCount,createMillis;
</code></pre><p>If it runs normally, you can use the <code>CALL gds.graph.list();</code> command to view the graph created.</p><h2 id="4-execute-the-wcc-algorithm-for-clustering">4 Execute the WCC Algorithm for Clustering</h2><p>Similarly, before running the algorithm, it is recommended to estimate memory resources. But I won&apos;t repeat it here. Run WCC using the following command. The <code>SET</code> instruction can assign a value to a new property, which is to label the cluster to which the client belongs. You can see that the code has excluded the situation where there is only one client in the cluster, because those people have no relationship with others.</p><pre><code class="language-sql">CALL gds.wcc.stream(&apos;WCC&apos;)
YIELD componentId,nodeId
WITH componentId AS cluster,gds.util.asNode(nodeId) AS client
WITH cluster, collect(client.id) AS clients --collect merges a sequence
WITH *,size(clients) AS clusterSize
WHERE clusterSize&gt;1
UNWIND clients AS client --UNWIND expands a sequence
MATCH(c:Client)
WHERE c.id=client
SET c.firstPartyFraudGroup=cluster;
</code></pre><p>The WCC algorithm helps to identify the population that needs attention, and subsequent algorithms can continue to be calculated based on the clustering results.</p><h2 id="5-conclusion">5 Conclusion</h2><p>This section completes the reintegration of the population relationship and identifies groups with similar characteristics, which is convenient for subsequent analysis. At the same time, the commonly used technical points are introduced, such as WITH, MERGE, SET, APOC, memory estimation, creating a graph, running graph algorithms, etc. In the next section, we will explain how to score dangerous populations and effectively identify fraudsters.</p>]]></content:encoded></item><item><title><![CDATA[Neo4J Graph Database Anti-Fraud Analysis in Practice (II) - Prepare Data]]></title><description><![CDATA[<h2 id="1-introduction">1 Introduction</h2><p>In the previous article <a href="https://realvincentyuan.github.io/Spacecraft/neo4j-graph-database-anti-fraud-analysis-practice-part-1-building-analysis-environment">Neo4J Graph Database Anti-Fraud Analysis in Practice (Part 1) - Setup Analysis Environment</a>, we introduced the Neo4J analysis platform and some basic operations of graph databases. In this article, we will officially start the exploration of the anti-fraud theme. The primary task is to</p>]]></description><link>https://realvincentyuan.github.io/Spacecraft/neo4j-graph-database-anti-fraud-analysis-in-practice-part-2-prepare-data/</link><guid isPermaLink="false">64a8bf074e1c2f000108efcb</guid><category><![CDATA[Tech]]></category><category><![CDATA[Knowledge Graph]]></category><category><![CDATA[Python]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sun, 06 Feb 2022 06:00:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1590859808308-3d2d9c515b1a?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDN8fE5ldHxlbnwwfHx8fDE2ODgyNjEwNTF8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<h2 id="1-introduction">1 Introduction</h2><img src="https://images.unsplash.com/photo-1590859808308-3d2d9c515b1a?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDN8fE5ldHxlbnwwfHx8fDE2ODgyNjEwNTF8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Neo4J Graph Database Anti-Fraud Analysis in Practice (II) - Prepare Data"><p>In the previous article <a href="https://realvincentyuan.github.io/Spacecraft/neo4j-graph-database-anti-fraud-analysis-practice-part-1-building-analysis-environment">Neo4J Graph Database Anti-Fraud Analysis in Practice (Part 1) - Setup Analysis Environment</a>, we introduced the Neo4J analysis platform and some basic operations of graph databases. In this article, we will officially start the exploration of the anti-fraud theme. The primary task is to clarify the goal, obtain and sort the data. The example provided by Neo4J focuses on fraudsters using the same entity information to control a large number of accounts to conduct fraudulent transactions. Therefore, the goal is to find the connections between these accounts and expose the criminal gangs. However, the example did not introduce the source and preparation of the data, which is actually vital in real work. Therefore, this article will focus on the data preparation part.</p><h2 id="2-obtain-data">2 Obtain Data</h2><p>Neo4J provides <a href="https://neo4j.com/developer/data-import/?ref=localhost">various methods</a> to connect to the data repository:</p><ul><li>Manually define the data</li><li>Import CSV file</li><li>Use API to import data</li><li>Import data from a relational database</li><li>Use an application-driven connection to import data (supporting multiple programming languages such as .Net, Java, JavaScript, Go, and Python, etc.)</li></ul><p>Personally, I prefer to use Python driver to import data because usually, we can first obtain the raw data in the relational database through Python, process it, and then use the Neo4J interface to connect multiple platforms to complete the data transfer work. In the face of large-scale data sets, using PySpark can further improve computing performance. Neo4J also provides <a href="https://neo4j.com/docs/spark/current/python/?ref=localhost">PySpark interface</a>, with very fast read and write speed. Here is an example PySpark code. Note that you need to download the corresponding <a href="https://github.com/neo4j-contrib/neo4j-spark-connector/releases?ref=localhost">Neo4j Connector for Apache Spark</a> Jar file before using it.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/1_V/Neo4J%E8%BF%9E%E6%8E%A5%E4%BF%A1%E6%81%AF.png" class="kg-image" alt="Neo4J Graph Database Anti-Fraud Analysis in Practice (II) - Prepare Data" loading="lazy"><figcaption>Neo4J Connection Information</figcaption></figure><pre><code class="language-python"># Read data from Neo4J
# Replace the account name and password with your own settings
df = spark.read.format(&quot;org.neo4j.spark.DataSource&quot;)\
     .option(&quot;url&quot;, &quot;bolt+s://63d2d43273493b399454b26961152ed9.neo4jsandbox.com:7687&quot;)\
     .option(&quot;authentication.type&quot;, &quot;basic&quot;)\
     .option(&quot;authentication.basic.username&quot;, &quot;neo4j&quot;)\
     .option(&quot;authentication.basic.password&quot;, &quot;password&quot;)\
     .option(&quot;labels&quot;, &quot;Person&quot;)\
     .load()

display(df)

# Write data to Neo4J
df2 = spark.createDataFrame( [(1, &quot;John&quot;),(2, &quot;Thomas&quot;)],
 [&quot;id&quot;, &quot;name&quot;]
)

df2.write.format(&quot;org.neo4j.spark.DataSource&quot;)\
     .option(&quot;url&quot;, &quot;bolt+s://63d2d43273493b399454b26961152ed9.neo4jsandbox.com:7687&quot;)\
     .option(&quot;authentication.type&quot;, &quot;basic&quot;)\
     .option(&quot;authentication.basic.username&quot;, &quot;neo4j&quot;)\
     .option(&quot;authentication.basic.password&quot;, &quot;password&quot;)\
     .option(&quot;labels&quot;, &quot;:Person&quot;)\
     .option(&quot;node.keys&quot;, &quot;id&quot;)\
     .mode(&quot;Overwrite&quot;)\
     .save()
</code></pre><p>Remember to <a href="https://neo4j.com/docs/cypher-manual/current/indexes-for-search-performance/?ref=localhost">define an index</a> before loading the data. This operation will significantly improve the program running speed.</p><h2 id="3-define-nodes-and-relationships">3 Define Nodes and Relationships</h2><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/1_V/%E8%8A%82%E7%82%B9%E5%92%8C%E5%85%B3%E7%B3%BB.png" class="kg-image" alt="Neo4J Graph Database Anti-Fraud Analysis in Practice (II) - Prepare Data" loading="lazy"><figcaption>Nodes and Relationships</figcaption></figure><p>As shown in the figure, the colored circles represent nodes, and the lines between nodes are their relationships. Intuitively, the raw data is a table, which contains some fields related to the target, and each field corresponds to an entity (node).</p><!--kg-card-begin: html--><table>
<thead>
<tr>
<th>Mule</th>
<th>Phone</th>
<th>Email</th>
</tr>
</thead>
<tbody>
<tr>
<td>John</td>
<td>888888888</td>
<td><a>demo@gmail.com</a></td>
</tr>
<tr>
<td>Tim</td>
<td>777777777</td>
<td><a>demo2@gmail.com</a></td>
</tr>
</tbody>
</table><!--kg-card-end: html--><p>Nodes can be written into Neo4J using the above code, and the relationships between entities that are useful for the goal can be defined <a href="https://neo4j.com/docs/cypher-manual/current/clauses/create/?ref=localhost#create-relationships">using Cypher</a>. For example, the fact that John has his own email can be defined as follows:</p><pre><code class="language-sql">MATCH
  (a:Mule),
  (b:Email)
WHERE a.Email = b.Email
CREATE (a)-[r:HAS_EMAIL]-&gt;(b)
RETURN type(r)
</code></pre><p>By analogy, relationships useful for the target can be defined in such a way.</p><h2 id="4-data-overview">4 Data Overview</h2><p>The first part of the anti-fraud example described the descriptive analysis of the data, such as the number of nodes and relationships, etc. This is helpful for understanding the data, checking data completeness, and ensuring that the data you need is stored in Neo4J according to the set goal. This module&apos;s content is relatively intuitive and will not be elaborated further.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/1_V/%E6%8F%8F%E8%BF%B0%E6%80%A7%E7%BB%9F%E8%AE%A1.png" class="kg-image" alt="Neo4J Graph Database Anti-Fraud Analysis in Practice (II) - Prepare Data" loading="lazy"><figcaption>Descriptive Analysis</figcaption></figure><h2 id="5-conclusion">5 Conclusion</h2><p>This article solved many of the initial doubts of graph database beginners, how to import data (usually tables) into Neo4J, and define nodes and relationships that serve the goal. Undoubtedly, this is the foundation of subsequent analysis work, and we can officially analyze the data for anti-fraud. I hope that this sharing will be helpful to you, and welcome to leave a message for discussion in the comments!</p>]]></content:encoded></item><item><title><![CDATA[Neo4J Graph Database Anti-Fraud Analysis in Practice (I) - Set Up Analysis Environment]]></title><description><![CDATA[<h2 id="1-introduction">1 Introduction</h2><p>In the article <a href="https://realvincentyuan.github.io/Spacecraft/introduction-to-graph-databases">An Introduction to Graph Databases</a>, we introduced the basic components of a graph, such as nodes, properties, and relationships, and also briefly described the advantages of graph databases over traditional relational databases. Starting from this article, we will use anti-fraud analysis as an example to</p>]]></description><link>https://realvincentyuan.github.io/Spacecraft/neo4j-graph-database-anti-fraud-analysis-practice-part-1-building-analysis-environment/</link><guid isPermaLink="false">64a8bf074e1c2f000108efc9</guid><category><![CDATA[Tech]]></category><category><![CDATA[Knowledge Graph]]></category><category><![CDATA[Python]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sat, 29 Jan 2022 06:00:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1590859808308-3d2d9c515b1a?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDN8fE5ldHxlbnwwfHx8fDE2ODgyNjEwNTF8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<h2 id="1-introduction">1 Introduction</h2><img src="https://images.unsplash.com/photo-1590859808308-3d2d9c515b1a?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDN8fE5ldHxlbnwwfHx8fDE2ODgyNjEwNTF8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Neo4J Graph Database Anti-Fraud Analysis in Practice (I) - Set Up Analysis Environment"><p>In the article <a href="https://realvincentyuan.github.io/Spacecraft/introduction-to-graph-databases">An Introduction to Graph Databases</a>, we introduced the basic components of a graph, such as nodes, properties, and relationships, and also briefly described the advantages of graph databases over traditional relational databases. Starting from this article, we will use anti-fraud analysis as an example to practice using graph databases in real-world applications!</p><p>In a fraud scenario, bad actors typically obtain real customer identity information through channels such as phishing, malware, and the dark web. With this information, they can take over accounts by tampering with verification information or directly using this information for fraudulent transactions. Moreover, bad actors usually have a certain number of devices, identity cards, emails, phone numbers, and other pieces of information to pass service provider verification checks. Therefore, there is a certain degree of connection between the hijacked account and the information of these bad actors. This practical series focuses on using graph databases to mine potential connections behind fraud, and this article will introduce the basic knowledge of the analysis environment and graph database queries.</p><h2 id="2-neo4j-graph-database">2 Neo4J Graph Database</h2><p>Neo4J is a graph database solution provider, and its official website provides a series of tutorials and research environments for readers to learn. This practical exercise uses the sample data and computing resources provided by its <a href="https://sandbox.neo4j.com/?ref=localhost">Sandbox</a>, which provides free instances for researchers to experiment with.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/1_V/Neo4J_Sandbox.png" class="kg-image" alt="Neo4J Graph Database Anti-Fraud Analysis in Practice (I) - Set Up Analysis Environment" loading="lazy" width="1954" height="744"><figcaption>Neo4J Sandbox</figcaption></figure><p>To get started, click &quot;Free Use&quot; to create a database, and find <code>Fraud Detection</code> to start exploring (remember the password)!</p><h2 id="3-cypher-query-language">3 Cypher Query Language</h2><p>Just as SQL (Structured Query Language) is used to query relational databases, Neo4J Graph Database also has its own query language - Cypher. In Cypher, parentheses () are used to query nodes, such as <code>(p:Person)</code>, where <code>p</code> is a variable and <code>Person</code> is the type of the node.</p><p>Square brackets should be used to query relationships, such as <code>[w:WORKS_FOR]</code>, where <code>w</code> is a variable and <code>WORKS_FOR</code> is the type of relationship. The combination of the two can query the graph that meets the conditions, such as querying the actors who appear in a movie:</p><pre><code class="language-sql">MATCH (p:Person)-[relatedTo]-(m:Movie {title: &quot;Cloud Atlas&quot;})
RETURN p, m, relatedTo
</code></pre><p>Here, <code>MATCH</code> defines the matching rules, and <code>RETURN</code> defines what to return. Properties are defined using curly braces {}, such as querying people who have acted in movies with Tom Hanks:</p><pre><code class="language-sql">MATCH (tom:Person {name: &apos;Tom Hanks&apos;})-[a:ACTED_IN]-&gt;(m:Movie)&lt;-[rel:ACTED_IN]-(p:Person)
return p, a, rel, m, tom
</code></pre><p>Cypher does not require table joins, so its query statements are as smooth as natural language. Neo4J provides a complete <a href="https://neo4j.com/docs/cypher-manual/4.2/?ref=localhost">Cypher operation manual</a>, which is also a good reference.</p><h2 id="4-using-graph-databases">4 Using Graph Databases</h2><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/1_V/Fraud%E6%93%8D%E4%BD%9C%E7%95%8C%E9%9D%A2.png" class="kg-image" alt="Neo4J Graph Database Anti-Fraud Analysis in Practice (I) - Set Up Analysis Environment" loading="lazy" width="2560" height="1376"><figcaption>Neo4J Operation Interface</figcaption></figure><p>After understanding the basics above, you can officially enter the graph database. Click on the <code>Fraud Detection</code> graph database and open it in the browser to see the operation interface. The sidebar displays information about the database, and the main interface on the right is the area where queries are constructed. The anti-fraud practical exercise can now officially begin!</p>]]></content:encoded></item><item><title><![CDATA[Introduction to Graph Databases]]></title><description><![CDATA[<h1 id="1-introduction">1. Introduction</h1><p>Have you ever heard of &quot;Graph Databases - Graph Database&quot;? Are they databases used to store pictures? Or are they databases that store data in the form of pictures? (Misconception) If you have been misled by these two sentences, then let&apos;s get into today&</p>]]></description><link>https://realvincentyuan.github.io/Spacecraft/introduction-to-graph-databases/</link><guid isPermaLink="false">64a8bf074e1c2f000108efca</guid><category><![CDATA[Tech]]></category><category><![CDATA[Knowledge Graph]]></category><category><![CDATA[Python]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Tue, 25 Jan 2022 06:00:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1590859808308-3d2d9c515b1a?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDN8fE5ldHxlbnwwfHx8fDE2ODgyNjEwNTF8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<h1 id="1-introduction">1. Introduction</h1><img src="https://images.unsplash.com/photo-1590859808308-3d2d9c515b1a?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDN8fE5ldHxlbnwwfHx8fDE2ODgyNjEwNTF8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Introduction to Graph Databases"><p>Have you ever heard of &quot;Graph Databases - Graph Database&quot;? Are they databases used to store pictures? Or are they databases that store data in the form of pictures? (Misconception) If you have been misled by these two sentences, then let&apos;s get into today&apos;s article.</p><h2 id="2-nodes-and-relationships">2. Nodes and Relationships</h2><p>Unlike traditional relational databases, graph databases consist of nodes and relationships (the connections between nodes). As shown in the figure below:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/1_V1.png" class="kg-image" alt="Introduction to Graph Databases" loading="lazy"><figcaption>Nodes and Relationships</figcaption></figure><h3 id="21-nodes">2.1 Nodes</h3><p>Nodes represent entities. A node is similar to a record in a relational database. In the above figure, the circular patterns represent nodes. The orange nodes represent movie entities, and the blue nodes represent specific individuals.</p><h3 id="22-relationships">2.2 Relationships</h3><p>The connection between two nodes is called a relationship. In the aforementioned figure, three types of &quot;person-movie&quot; relationships are present:</p><ul><li><code>ACTED_IN</code> - Involves actors such as Keanu Reeves, Laurence Fishburne, Carrie-Anne Moss, and Hugo Weaving.</li><li><code>DIRECTED</code> - Directed by the Wachowski sisters.</li><li><code>PRODUCED</code> - Produced by Joel Silver.</li></ul><h3 id="23-relationship-direction">2.3 Relationship Direction</h3><p>In Neo4J, relationships have a direction. For a node, a relationship can have two directions: pointing to it or pointing from it to other nodes. In the above figure, all relationships are directed from a person to a movie.</p><h3 id="24-labels">2.4 Labels</h3><p>Labels represent the type of a node or relationship. In the above figure, when defining blue nodes, their labels are &quot;Person,&quot; and when defining orange nodes, their labels are &quot;Movie.&quot; Labels serve the purpose of returning only specific types of nodes when querying. For example, querying only &quot;Person&quot; nodes.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/1_V2.png" class="kg-image" alt="Introduction to Graph Databases" loading="lazy"><figcaption>Labels</figcaption></figure><h3 id="25-properties">2.5 Properties</h3><p>Both nodes and relationships can have properties. Properties are added in the form of name-value pairs. For example, retrieving the name and birth year properties of all Person nodes in the above figure. Properties make the information in a graph database more rich, and they can also be utilized in queries, such as querying people born after 1970.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/1_V3.png" class="kg-image" alt="Introduction to Graph Databases" loading="lazy"><figcaption>Properties</figcaption></figure><h2 id="3-why-graph-databases">3. Why Graph Databases?</h2><p>After getting a general introduction to graph databases, you may find this technology fascinating. What value can graph</p><p>databases bring to specific businesses that relational databases cannot? The following two aspects can serve as reference:</p><ul><li>Efficiently query relationships between data, especially when the relationships are complex.</li><li>Conveniently visualize relationships between data.</li></ul><p>When you see query results like the following, isn&apos;t it pleasing to the eye? The relationships between movies and people are clear at a glance. Of course, this is only a small part of the query results.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/1_V4.png" class="kg-image" alt="Introduction to Graph Databases" loading="lazy"><figcaption>Visualization of Results - 1</figcaption></figure><p>As the data increases, the visualization results may look like this...</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/1_V5.png" class="kg-image" alt="Introduction to Graph Databases" loading="lazy"><figcaption>Visualization of Results - 2</figcaption></figure><p>Of course, no one would extract valuable information from such visualization results. So how should graph databases be applied in specific business scenarios? Stay tuned for the upcoming practical series on graph databases, which will give you a more concrete understanding of this innovative and trendy technology! I hope this sharing has been helpful to you. </p>]]></content:encoded></item><item><title><![CDATA[Permutation Importance for Feature Selection]]></title><description><![CDATA[<h2 id="1-introduction">1 Introduction</h2><p>In previous articles like <a href="https://realvincentyuan.github.io/Spacecraft/decision-tree-learning-notes">Decision Tree Notes</a>, some common feature selection techniques have been introduced. In this article, we will continue to focus on this topic and explain a new method for assessing feature importance: Permutation Importance. </p><h2 id="2-algorithm-deconstruction">2 Algorithm Deconstruction</h2><p>Permutation Importance is suitable for tabular data, and</p>]]></description><link>https://realvincentyuan.github.io/Spacecraft/permutation-importance-for-feature-selection/</link><guid isPermaLink="false">64a8bf074e1c2f000108efc8</guid><category><![CDATA[Tech]]></category><category><![CDATA[AI]]></category><category><![CDATA[Python]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sat, 22 Jan 2022 06:00:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1591453089816-0fbb971b454c?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDh8fG1hY2hpbmUlMjBsZWFybmluZ3xlbnwwfHx8fDE2ODY1MTkyMzN8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<h2 id="1-introduction">1 Introduction</h2><img src="https://images.unsplash.com/photo-1591453089816-0fbb971b454c?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDh8fG1hY2hpbmUlMjBsZWFybmluZ3xlbnwwfHx8fDE2ODY1MTkyMzN8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Permutation Importance for Feature Selection"><p>In previous articles like <a href="https://realvincentyuan.github.io/Spacecraft/decision-tree-learning-notes">Decision Tree Notes</a>, some common feature selection techniques have been introduced. In this article, we will continue to focus on this topic and explain a new method for assessing feature importance: Permutation Importance. </p><h2 id="2-algorithm-deconstruction">2 Algorithm Deconstruction</h2><p>Permutation Importance is suitable for tabular data, and its assessment of feature importance depends on the extent to which the model performance score decreases when the feature is randomly rearranged. Its mathematical expression can be represented as:</p><figure class="kg-card kg-image-card"><img src="https://realvincentyuan.github.io/Spacecraft/content/images/2023/07/image-15.png" class="kg-image" alt="Permutation Importance for Feature Selection" loading="lazy" width="1528" height="742" srcset="https://realvincentyuan.github.io/Spacecraft/content/images/size/w600/2023/07/image-15.png 600w, https://realvincentyuan.github.io/Spacecraft/content/images/size/w1000/2023/07/image-15.png 1000w, https://realvincentyuan.github.io/Spacecraft/content/images/2023/07/image-15.png 1528w" sizes="(min-width: 720px) 720px"></figure><h2 id="3-example-code">3 Example Code</h2><pre><code class="language-python">from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Ridge
from sklearn.inspection import permutation_importance
diabetes = load_diabetes()
X_train, X_val, y_train, y_val = train_test_split(
    diabetes.data, diabetes.target, random_state=0)

model = Ridge(alpha=1e-2).fit(X_train, y_train)
model.score(X_val, y_val)


scoring = [&apos;r2&apos;, &apos;neg_mean_absolute_percentage_error&apos;, &apos;neg_mean_squared_error&apos;]
# The scoring parameter can include multiple calculation indicators at the same time. This is more efficient than using permutation_importance repeatedly, because the predicted value can be used to calculate different indicators.
r_multi = permutation_importance(model, X_val, y_val, n_repeats=30, random_state=0, scoring=scoring)

for metric in r_multi:
    print(f&quot;{metric}&quot;)
    r = r_multi[metric]
    for i in r.importances_mean.argsort()[::-1]:
        if r.importances_mean[i] - 2 * r.importances_std[i] &gt; 0:
            print(f&quot;    {diabetes.feature_names[i]:&lt;8}&quot;
                  f&quot;{r.importances_mean[i]:.3f}&quot;
                  f&quot; +/- {r.importances_std[i]:.3f}&quot;)

</code></pre><p>The output is:</p><pre><code class="language-python">r2
  s5      0.204 +/- 0.050
  bmi     0.176 +/- 0.048
  bp      0.088 +/- 0.033
  sex     0.056 +/- 0.023
neg_mean_absolute_percentage_error
  s5      0.081 +/- 0.020
  bmi     0.064 +/- 0.015
  bp      0.029 +/- 0.010
neg_mean_squared_error
  s5      1013.903 +/- 246.460
  bmi     872.694 +/- 240.296
  bp      438.681 +/- 163.025
  sex     277.382 +/- 115.126
</code></pre><h2 id="4-conclusion">4 Conclusion</h2><p>Compared with tree models, feature importance is usually judged based on the decrease in impurity, which is usually based on the <code>training set</code>. When the model is overfitting, the importance of features is misleading. In this case, seemingly important features may not have satisfactory predictive power for new data encountered by the model online.</p><p>At the same time, feature importance based on reduction in impurity is easily affected by high-cardinality features, so numerical variables often rank higher. In contrast, Permutation Importance has no bias towards model features and is not limited to specific model types, so it has a wide range of applications. Please note that if the features have strong multicollinearity, it is recommended to take only one important feature. The method can be viewed in this <a href="https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance_multicollinear.html?ref=localhost#sphx-glr-auto-examples-inspection-plot-permutation-importance-multicollinear-py">example</a>.</p><p>At the same time, <code>Scikit Learn</code> also provides an intuitive <a href="https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance.html?ref=localhost#sphx-glr-auto-examples-inspection-plot-permutation-importance-py">example</a> to demonstrate the difference between feature importance based on impurity reduction and Permutation Importance.</p><p>Hope this sharing is helpful to you, and welcome to leave comments for discussion!</p>]]></content:encoded></item><item><title><![CDATA[Automatically Build and Push Docker Image with GitHub Action]]></title><description><![CDATA[<h2 id="1-introduction">1 Introduction</h2><p>In this article, we will introduce how to use GitHub Action to automatically push Docker images to a registry, greatly simplifying the tedious process of building and pushing images! We have introduced many cool features of GitHub before. To facilitate the understanding of the content of this article,</p>]]></description><link>https://realvincentyuan.github.io/Spacecraft/automatically-build-and-push-docker-image-with-github-action/</link><guid isPermaLink="false">64a8bf074e1c2f000108efc7</guid><category><![CDATA[Tech]]></category><category><![CDATA[Git]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sat, 20 Nov 2021 06:00:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1591608516485-a1a53df39498?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDZ8fGdpdGh1YnxlbnwwfHx8fDE2ODY1MTI2NjJ8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<h2 id="1-introduction">1 Introduction</h2><img src="https://images.unsplash.com/photo-1591608516485-a1a53df39498?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDZ8fGdpdGh1YnxlbnwwfHx8fDE2ODY1MTI2NjJ8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Automatically Build and Push Docker Image with GitHub Action"><p>In this article, we will introduce how to use GitHub Action to automatically push Docker images to a registry, greatly simplifying the tedious process of building and pushing images! We have introduced many cool features of GitHub before. To facilitate the understanding of the content of this article, we recommend reviewing the basic GitHub operation knowledge in the previous article, especially GitHub Action:</p><ul><li><a href="https://realvincentyuan.github.io/Spacecraft/how-to-use-github-without-writing-a-single-line-of-code">Teaching You to Use GitHub with One Line of Code</a></li><li><a href="https://realvincentyuan.github.io/Spacecraft/a-list-of-common-git-commands">Git Common Commands Overview</a></li><li><a href="https://realvincentyuan.github.io/Spacecraft/creating-a-beautiful-online-resume-using-github">Create a Beautiful Online Resume with GitHub</a></li><li><a href="https://realvincentyuan.github.io/Spacecraft/github-action-overview">Overview of GitHub Action</a></li></ul><h2 id="2-configure-the-image-registry">2 Configure the Image Registry</h2><p>Here we take Aliyun&apos;s image registry as an example for demonstration. The principles of other image registries are similar and can be applied by analogy. First, log in to the <a href="https://cr.console.aliyun.com/cn-shanghai/instance/repositories?ref=localhost">Aliyun image registry</a>, and perform the following operations:</p><ul><li>Create a namespace as a collection of image repositories, named after the company or organization. We use <code>bullettech_services</code>.</li><li>Create an image repository as a collection of images that can store different versions of images in the repository.</li></ul><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/registry.png" class="kg-image" alt="Automatically Build and Push Docker Image with GitHub Action" loading="lazy"><figcaption>Image Registry</figcaption></figure><h2 id="3-configure-the-github-action">3 Configure the GitHub Action</h2><h3 id="31-configure-the-password">3.1 Configure the Password</h3><p>Set a password in the GitHub repository for logging in to the image registry. You can find the password in the repository settings and then store the login name and password of the image registry service.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/secrets.png" class="kg-image" alt="Automatically Build and Push Docker Image with GitHub Action" loading="lazy"><figcaption>Store the login name and password of the image registry service</figcaption></figure><h3 id="32-create-the-workflow">3.2 Create the Workflow</h3><p>First, create a workflow in the <code>.github/workflows</code> directory, such as <code>ci.yml</code>, and understand the commands based on the comments, and modify them according to the project situation.</p><pre><code class="language-yml">name: actions

on: [push, pull_request] # Trigger Event

jobs:
  bt-product-release:
    if: ${{ github.ref == &apos;refs/heads/main&apos; }}  # Check if the main branch is updated
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2 # pull the code to the running server
    - name: Login to Aliyun Container Registry (ACR)
      uses: aliyun/acr-login@v1 # Use the Aliyun Image Service Action
      with:
        login-server: registry.cn-shanghai.aliyuncs.com # Be sure to correctly fill in the login address of the image registry service
        region-id: cn-shanghai
        username: &quot;${{ secrets.REGISTRY_USERNAME }}&quot; # Reference the username of the image registry service set in GitHub repo
        password: &quot;${{ secrets.REGISTRY_PASSWORD }}&quot; # Reference the password of the image registry service set in GitHub repo
    - name: Build and Push Docker Image
      env:
        IMAGE_TAG: ${{ github.sha }} # Used to mark the container version number
      run: |
        docker build -t registry.cn-shanghai.aliyuncs.com/bullettech_services/app:$IMAGE_TAG .
        docker push registry.cn-shanghai.aliyuncs.com/bullettech_services/app:$IMAGE_TAG
</code></pre><p>This way, every time the main branch is updated, GitHub will build the image based on the updated code, and push the image to the designated image repository (pay attention to the version):</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/images.png" class="kg-image" alt="Automatically Build and Push Docker Image with GitHub Action" loading="lazy"><figcaption>Image</figcaption></figure><h2 id="4-conclusion">4 Conclusion</h2><p>This efficient workflow saves a lot of time and avoids many errors that are prone to occur during manual operations. GitHub Action is so awesome!</p><p>I hope this sharing will help you, and welcome to leave a message in the comments to discuss!</p>]]></content:encoded></item><item><title><![CDATA[GitHub Action Overview]]></title><description><![CDATA[<h2 id="1-introduction">1 Introduction</h2><p>We have introduced many cool features of GitHub before. To better understand the content of this article, it is recommended to review the basic GitHub operation knowledge in the previous articles:</p><ul><li><a href="https://realvincentyuan.github.io/Spacecraft/how-to-use-github-without-writing-a-single-line-of-code">Teach You How to Use GitHub without Writing Any Code</a></li><li><a href="https://realvincentyuan.github.io/Spacecraft/a-list-of-common-git-commands">Git Commonly Used Commands</a></li><li><a href="https://realvincentyuan.github.io/Spacecraft/creating-a-beautiful-online-resume-using-github">Create a Beautiful</a></li></ul>]]></description><link>https://realvincentyuan.github.io/Spacecraft/github-action-overview/</link><guid isPermaLink="false">64a8bf074e1c2f000108efc6</guid><category><![CDATA[Tech]]></category><category><![CDATA[Git]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sat, 13 Nov 2021 06:00:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1591608516485-a1a53df39498?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDZ8fGdpdGh1YnxlbnwwfHx8fDE2ODY1MTI2NjJ8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<h2 id="1-introduction">1 Introduction</h2><img src="https://images.unsplash.com/photo-1591608516485-a1a53df39498?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDZ8fGdpdGh1YnxlbnwwfHx8fDE2ODY1MTI2NjJ8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="GitHub Action Overview"><p>We have introduced many cool features of GitHub before. To better understand the content of this article, it is recommended to review the basic GitHub operation knowledge in the previous articles:</p><ul><li><a href="https://realvincentyuan.github.io/Spacecraft/how-to-use-github-without-writing-a-single-line-of-code">Teach You How to Use GitHub without Writing Any Code</a></li><li><a href="https://realvincentyuan.github.io/Spacecraft/a-list-of-common-git-commands">Git Commonly Used Commands</a></li><li><a href="https://realvincentyuan.github.io/Spacecraft/creating-a-beautiful-online-resume-using-github">Create a Beautiful Online Resume Using GitHub</a></li></ul><p>In this article, we will introduce how to use GitHub Actions to simplify repeated mechanical tasks and greatly improve efficiency and save time.</p><h2 id="2-github-action-overview">2 GitHub Action Overview</h2><p>GitHub Action can automatically execute custom scripts to complete preset work. Users need to set the triggering conditions (events) and the commands to be executed when the conditions are met. GitHub can automatically complete the preset operations, for example, when a update is merged to the master/main branch, automatically execute the test script to check for errors. The following figure shows the components when GitHub Action is executed:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/overview-actions-design.png" class="kg-image" alt="GitHub Action Overview" loading="lazy"><figcaption>GitHub Action components, source: GitHub</figcaption></figure><p>When an event occurs, GitHub automatically triggers the workflow. Then the program executes step by step.</p><h2 id="3-create-action">3 Create Action</h2><p>GitHub Action uses <a href="https://yaml.org/?ref=localhost">YAML</a> to define the triggered events, work, and steps. The workflow file needs to be stored in a specific location in the code repository: <code>.github/workflows</code>.</p><p>Take the continuous integration workflow of the <a href="https://github.com/BulletTech/BulletTech/blob/main/.github/workflows/ci.yml?ref=localhost">BulletTech blog</a> as an example:</p><pre><code class="language-yml">name: ci
on:
  push:
    branches:
      - main
jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-python@v2
        with:
          python-version: 3.x
      - run: python ./docs/Scripts/Update_reading_time.py
      - run: pip install mkdocs-material
      - run: pip install mkdocs-redirects
      - run: pip install mkdocs-minify-plugin
      - run: pip install mkdocs-macros-plugin
      - run: pip install mkdocs-git-revision-date-localized-plugin
      - run: pip install --upgrade mkdocs-material
      - run: pip install --upgrade mkdocs-redirects
      - run: pip install --upgrade mkdocs-minify-plugin
      - run: pip install --upgrade mkdocs-macros-plugin
      - run: pip install --upgrade mkdocs-git-revision-date-localized-plugin   
      - run: git pull
      - run: mkdocs gh-deploy --force
</code></pre><p>Key points are as follows:</p><ul><li><code>name</code> defines the name of the workflow, in this case, continuous integration (CI).</li><li><code>on</code> is the event that triggers the workflow. Here, it is defined that the command needs to be executed when a push is updated to the main branch.</li><li><code>jobs</code> defines the work tasks. <code>deploy</code> is the name of the work. It runs a series of steps on GitHub&apos;s Ubuntu Linux virtual machine.</li><li><code>uses</code> is followed by an action in GitHub Action Marketplace. Here, actions are used to check out the repository and download the code to the server that runs the code, and configure the Python runtime environment.</li><li><code>run</code> is followed by the command to be executed. Here, some Python packages required by the blog are installed and the deployment command is run.</li></ul><h2 id="4-check-action-status">4 Check Action Status</h2><p>In the Actions tab of the GitHub repository, you can see the running status of the action:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/Action_Status.png" class="kg-image" alt="GitHub Action Overview" loading="lazy"><figcaption>GitHub Action status</figcaption></figure><p>You can see the <code>ci</code> workflow used by BulletTech, and click on <code>runs</code> to view the running status of each step of the action.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/Action_steps.png" class="kg-image" alt="GitHub Action Overview" loading="lazy"><figcaption>Action running status</figcaption></figure><h2 id="5-conclusion">5 Conclusion</h2><p>Using GitHub Action automates many repetitive and mechanical labor tasks, saving time that can be used for more meaningful things. For more information, please refer to the following reference materials to customize your own workflow.</p><p>I hope this sharing can help you. Feel free to leave a comment in the comment section for discussion!</p>]]></content:encoded></item><item><title><![CDATA[Creating a Beautiful Online Resume using GitHub]]></title><description><![CDATA[<h2 id="1-introduction">1 Introduction</h2><p>We have previously introduced many cool features of GitHub. To better understand the content of this article, it is recommended to read previous articles to review the basic knowledge of GitHub operations:</p><ul><li><a href="https://realvincentyuan.github.io/Spacecraft/how-to-use-github-without-writing-a-single-line-of-code">Teaching You to Use GitHub without Writing a Single Line of Code</a></li><li><a href="https://realvincentyuan.github.io/Spacecraft/a-list-of-common-git-commands">Git Commonly Used Commands</a></li></ul>]]></description><link>https://realvincentyuan.github.io/Spacecraft/creating-a-beautiful-online-resume-using-github/</link><guid isPermaLink="false">64a8bf074e1c2f000108efc5</guid><category><![CDATA[Tech]]></category><category><![CDATA[Git]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Wed, 03 Nov 2021 05:00:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1591608516485-a1a53df39498?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDZ8fGdpdGh1YnxlbnwwfHx8fDE2ODY1MTI2NjJ8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<h2 id="1-introduction">1 Introduction</h2><img src="https://images.unsplash.com/photo-1591608516485-a1a53df39498?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDZ8fGdpdGh1YnxlbnwwfHx8fDE2ODY1MTI2NjJ8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Creating a Beautiful Online Resume using GitHub"><p>We have previously introduced many cool features of GitHub. To better understand the content of this article, it is recommended to read previous articles to review the basic knowledge of GitHub operations:</p><ul><li><a href="https://realvincentyuan.github.io/Spacecraft/how-to-use-github-without-writing-a-single-line-of-code">Teaching You to Use GitHub without Writing a Single Line of Code</a></li><li><a href="https://realvincentyuan.github.io/Spacecraft/a-list-of-common-git-commands">Git Commonly Used Commands</a></li></ul><p>In this article, we will introduce how to use GitHub to create an online resume and build a website that everyone can access to showcase oneself.</p><h2 id="2-creating-an-online-resume">2 Creating an Online Resume</h2><h3 id="21-downloading-example-code">2.1 Downloading Example Code</h3><p>This example uses a Bootstrap template, please go to BulletTech&apos;s official GitHub account and find the [Resume repository](<a href="https://github.com/BulletTech2021/Resume?ref=localhost">https://github.com/BulletTech2021/Resume</a> &apos;BulletTech&apos;s Resume Example Code&apos;) to download the example code.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/Resume%E4%BB%93%E5%BA%93.png" class="kg-image" alt="Creating a Beautiful Online Resume using GitHub" loading="lazy"><figcaption>BulletTech&apos;s Resume Repository</figcaption></figure><p>The code that needs to be modified exists in <code>/home/index.html</code>:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/home%E6%BA%90%E4%BB%A3%E7%A0%81.png" class="kg-image" alt="Creating a Beautiful Online Resume using GitHub" loading="lazy"><figcaption>Homepage Source Code</figcaption></figure><h3 id="22-modifying-example-code">2.2 Modifying Example Code</h3><p>After downloading the source code, double-click <code>index.html</code> to preview it in real-time. Use <code>ctrl/command+F</code> to find and modify the corresponding elements in comparison with the webpage content. The webpage will display the latest content after refreshing. You can also modify the CSS (<code>home/css/styles.css</code>) and other components for deep customization.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/Resume.png" class="kg-image" alt="Creating a Beautiful Online Resume using GitHub" loading="lazy"><figcaption>Previewing the Resume on Local Machine</figcaption></figure><h3 id="23-publishing-the-resume">2.3 Publishing the Resume</h3><p>Create your own GitHub repository and submit the modified code to your repository. Check the website to ensure that the complete code is uploaded. Then activate the GitHub Pages feature. By default, select root under the master/main branch. Click on the corresponding URL to access your own resume.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/GitHub_Pages.png" class="kg-image" alt="Creating a Beautiful Online Resume using GitHub" loading="lazy"><figcaption>Setting Up GitHub Pages</figcaption></figure><h2 id="3-conclusion">3 Conclusion</h2><p>We have added another little trick to the use of GitHub. You are welcome to use the above steps to create your own online resume. BulletTech&apos;s <a href="https://bullettech2021.github.io/Resume/home/?ref=localhost">example resume</a> can be accessed at <code>https://bullettech2021.github.io/Resume/home/</code>.</p><p>Hope this sharing is helpful to you. Welcome to leave a message in the comments area for discussion!</p>]]></content:encoded></item><item><title><![CDATA[PicGo Image Hosting Tool, Just Right!]]></title><description><![CDATA[<h2 id="1-introduction">1 Introduction</h2><p>Pictures are indispensable in the workflow of self-media. A good image hosting can conveniently manage and reference pictures. In the article &quot;How to write a beautiful WeChat article in the quickest way possible,&quot; we introduced how to build an effective workflow. However, for some reasons, the</p>]]></description><link>https://realvincentyuan.github.io/Spacecraft/picgo-image-hosting-just-right/</link><guid isPermaLink="false">64a8bf074e1c2f000108efc4</guid><category><![CDATA[Tech]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sat, 23 Oct 2021 05:00:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1508004680771-708b02aabdc0?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDExfHxwaWN0dXJlfGVufDB8fHx8MTY4NjUxNzY4MHww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<h2 id="1-introduction">1 Introduction</h2><img src="https://images.unsplash.com/photo-1508004680771-708b02aabdc0?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDExfHxwaWN0dXJlfGVufDB8fHx8MTY4NjUxNzY4MHww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="PicGo Image Hosting Tool, Just Right!"><p>Pictures are indispensable in the workflow of self-media. A good image hosting can conveniently manage and reference pictures. In the article &quot;How to write a beautiful WeChat article in the quickest way possible,&quot; we introduced how to build an effective workflow. However, for some reasons, the GitHub image hosting in mdnice is no longer available. Therefore, we introduce a new practical image hosting tool - PicGo in this article.</p><h2 id="2-install-picgo">2 Install PicGo</h2><p>PicGo supports Windows, macOS, and Linux platforms, and installation files for each platform can be downloaded from its <a href="https://github.com/Molunerfinn/PicGo/releases?ref=localhost">GitHub official website</a>.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/%E4%B8%8B%E8%BD%BDPicGo.png" class="kg-image" alt="PicGo Image Hosting Tool, Just Right!" loading="lazy"><figcaption>Download PicGo</figcaption></figure><p>After installation, you can see the main interface of PicGo:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/PicGo%E4%B8%BB%E7%95%8C%E9%9D%A2.png" class="kg-image" alt="PicGo Image Hosting Tool, Just Right!" loading="lazy"><figcaption>PicGo main interface</figcaption></figure><p>Different functions can be switched on the left-hand side. As shown in the figure, the upload area is the same as all the uploaded pictures in the album. The configuration area will be introduced in detail below.</p><h2 id="3-configure-github-image-hosting">3 Configure GitHub Image Hosting</h2><p>PicGo supports multiple image hosting, such as SMMS, Qiniu Image Hosting, Tencent Cloud COS, UpYun Image Hosting, GitHub Image Hosting, Alibaba Cloud OSS, Imgur Image Hosting, etc. This tutorial uses the free GitHub Image Hosting as an example to describe the configuration process.</p><p>Firstly, a GitHub account is necessary, and basic GitHub operations need to be familiar with. You can refer to the article &#x201C;Teaches You to Use GitHub Without Writing a Line of Code&#x201D; for learning. After registering for GitHub, generate Personal Access Tokens in <code>Personal Access Tokens</code> -&gt; <code>Developer Settings</code>. Only check the box for the repo to generate the token. As it is only displayed once, please be sure to save the token for later use.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/Personal_access_tokens.png" class="kg-image" alt="PicGo Image Hosting Tool, Just Right!" loading="lazy"><figcaption>Personal access tokens</figcaption></figure><p>Then configure parameters as shown below:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/%E9%85%8D%E7%BD%AEPicGo.png" class="kg-image" alt="PicGo Image Hosting Tool, Just Right!" loading="lazy"><figcaption>Configure PicGo</figcaption></figure><p>Generally, selecting the main branch is sufficient, but please note that it is best to specify the storage path to a folder rather than all piled up in the root directory of the branch. At the same time, setting a custom domain name can speed up the loading of images. BulletTech uses <code>https://cdn.jsdelivr.net/gh/BulletTech2021/Pics</code>.</p><p>After the configuration is complete, drag the picture to the upload area, and you can see that the picture will be uploaded to GitHub automatically. At the same time, the image reference link (<code>https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/Pics_in_github.png</code>) is automatically copied to the clipboard. This link can be used on various platforms to display the image.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/Pics_in_github.png" class="kg-image" alt="PicGo Image Hosting Tool, Just Right!" loading="lazy"><figcaption>The image has been uploaded to GitHub</figcaption></figure><h2 id="4-conclusion">4 Conclusion</h2><p>PicGo is open-source and free. It has stable and reliable software quality and the developer is still updating the software. You can also conduct secondary development based on its foundation. This practical tool can significantly improve the efficiency of self-media workers!</p><p>I hope this sharing can be helpful to you. Welcome to leave a message in the comment section for discussion.</p>]]></content:encoded></item><item><title><![CDATA[SnowFlake Database Permission Overview]]></title><description><![CDATA[<h2 id="1-introduction">1 Introduction</h2><p>Properly managing permissions for objects (such as databases and tables) in a database is very important but often overlooked. When it comes to permission issues and problems, people will regret not taking permission management seriously. Therefore, this article will take the very popular SnowFlake data warehouse as an</p>]]></description><link>https://realvincentyuan.github.io/Spacecraft/snowflake-permission-overview/</link><guid isPermaLink="false">64a8bf074e1c2f000108efc3</guid><category><![CDATA[Tech]]></category><category><![CDATA[Analytics]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Mon, 11 Oct 2021 05:00:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1457269449834-928af64c684d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDF8fHNub3dmbGFrZXxlbnwwfHx8fDE2ODY1MTYyMzN8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<h2 id="1-introduction">1 Introduction</h2><img src="https://images.unsplash.com/photo-1457269449834-928af64c684d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDF8fHNub3dmbGFrZXxlbnwwfHx8fDE2ODY1MTYyMzN8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="SnowFlake Database Permission Overview"><p>Properly managing permissions for objects (such as databases and tables) in a database is very important but often overlooked. When it comes to permission issues and problems, people will regret not taking permission management seriously. Therefore, this article will take the very popular SnowFlake data warehouse as an example, succinctly explaining important concepts and commonly used commands for permission management. It is recommended to like and bookmark for later review and use!</p><h2 id="2-snowflake-permission-control-framework">2 SnowFlake Permission Control Framework</h2><p>SnowFlake has two permission control models:</p><ul><li>Discretionary Access Control (DAC): Each object has an owner who can grant different permissions to others.</li><li>Role-based Access Control (RBAC): Access permissions are controlled by roles, which can be assigned to different users.</li></ul><p>In SnowFlake, there are some important concepts that help understand permission control:</p><ul><li>Securable object: An entity that can be granted specific permissions. If you do not have permission, access to the object will be denied.</li><li>Role: An entity that can receive permissions, which can be assigned to users or other roles to form different role hierarchies.</li><li>Privilege: The level of access control for objects. By setting different privileges, the granularity of access control can be controlled.</li><li>User: An identity that can be recognized by SnowFlake and can be a person or a program.</li></ul><p>In SnowFlake, the permission control of securable objects is shown in the figure below. Access to securable objects can be granted by assigning permissions to roles, which means that permissions are assigned to other roles or objects. In addition, each securable object has an owner who can grant permissions to other roles.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://cdn.jsdelivr.net/gh/BulletTech2021/Pics/img/access-control-relationships.png" class="kg-image" alt="SnowFlake Database Permission Overview" loading="lazy"><figcaption>SnowFlake Permission Control Diagram</figcaption></figure><h2 id="3-common-commands">3 Common Commands</h2><p>After a basic understanding of how SnowFlake manages permissions, using commands to operate and view permissions will be more convenient.</p><h3 id="31-granting-permissions">3.1 Granting Permissions</h3><pre><code class="language-sql">GRANT {  { globalPrivileges         | ALL [ PRIVILEGES ] } ON ACCOUNT
       | { accountObjectPrivileges  | ALL [ PRIVILEGES ] } ON { USER | RESOURCE MONITOR | WAREHOUSE | DATABASE | INTEGRATION } &lt;object_name&gt;
       | { schemaPrivileges         | ALL [ PRIVILEGES ] } ON { SCHEMA &lt;schema_name&gt; | ALL SCHEMAS IN DATABASE &lt;db_name&gt; }
       | { schemaPrivileges         | ALL [ PRIVILEGES ] } ON { FUTURE SCHEMAS IN DATABASE &lt;db_name&gt; }
       | { schemaObjectPrivileges   | ALL [ PRIVILEGES ] } ON { &lt;object_type&gt; &lt;object_name&gt; | ALL &lt;object_type_plural&gt; IN { DATABASE &lt;db_name&gt; | SCHEMA &lt;schema_name&gt; } }
       | { schemaObjectPrivileges   | ALL [ PRIVILEGES ] } ON FUTURE &lt;object_type_plural&gt; IN { DATABASE &lt;db_name&gt; | SCHEMA &lt;schema_name&gt; }
      }
  TO [ ROLE ] &lt;role_name&gt; [ WITH GRANT OPTION ]
</code></pre><p>Where:</p><pre><code class="language-sql">globalPrivileges ::=
  { { CREATE { ROLE | USER | WAREHOUSE | DATABASE | INTEGRATION } } | APPLY MASKING POLICY | APPLY ROW ACCESS POLICY | APPLY TAG | EXECUTE TASK | MANAGE GRANTS | MONITOR { EXECUTION | USAGE }  } [ , ... ]

accountObjectPrivileges ::=
-- For USER
  { MONITOR } [ , ... ]
-- For RESOURCE MONITOR
  { MODIFY | MONITOR } [ , ... ]
-- For WAREHOUSE
  { MODIFY | MONITOR | USAGE | OPERATE } [ , ... ]
-- For DATABASE
  { MODIFY | MONITOR | USAGE | CREATE SCHEMA | IMPORTED PRIVILEGES } [ , ... ]
-- For INTEGRATION
  { USAGE | USE_ANY_ROLE } [ , ... ]

schemaPrivileges ::=
    { MODIFY | MONITOR | USAGE | CREATE { TABLE | EXTERNAL TABLE | VIEW | MATERIALIZED VIEW | MASKING POLICY | ROW ACCESS POLICY | TAG | SEQUENCE | FUNCTION | PROCEDURE | FILE FORMAT | STAGE | PIPE | STREAM | TASK } } [ , ... ]

schemaObjectPrivileges ::=
    -- For TABLE
      { SELECT | INSERT | UPDATE | DELETE | TRUNCATE | REFERENCES } [ , ... ]
    -- For VIEW
      { SELECT | REFERENCES } [ , ... ]
    -- For MATERIALIZED VIEW
        SELECT
    -- For SEQUENCE, FUNCTION (UDF or external function), PROCEDURE, or FILE FORMAT
        USAGE
    -- For internal STAGE
        READ [ , WRITE ]
    -- For external STAGE
        USAGE
    -- For PIPE
       { MONITOR | OPERATE } [ , ... ]
    -- For STREAM
        SELECT
    -- For TASK
       { MONITOR | OPERATE } [ , ... ]
    -- For MASKING POLICY
        APPLY
    -- For ROW ACCESS POLICY
        APPLY
    -- For TAG
        APPLY
</code></pre><p>The full list of all permissions can be found in SnowFlake&apos;s <a href="https://docs.snowflake.com/en/user-guide/security-access-control-privileges.html?ref=localhost">API documentation</a>.</p><p>The required parameters are <code>object_name</code>, <code>object_type</code>, <code>object_type_plural</code>, and <code>role_name</code>, which are self-explanatory. Optional parameters include:</p><ul><li><code>ON FUTURE</code>: Specifies that the permission is granted to tables or views in a new database or schema, not existing objects.</li><li><code>WITH GRANT OPTION</code>: Specifies whether the recipient role is allowed to grant permissions to other roles.</li></ul><p>Examples are as follows:</p><pre><code class="language-sql"># Specify that the role can continue to grant permissions with grant option
grant operate on warehouse report_wh to role analyst with grant option;

# Grant select permission on all tables in schema mydb.myschema to role analyst
grant select on all tables in schema mydb.myschema to role analyst;
</code></pre><h3 id="32-viewing-permissions">3.2 Viewing Permissions</h3><p>You can view object permissions using the <code>SHOW GRANTS</code> command, as shown below:</p><pre><code class="language-sql">SHOW GRANTS ON ACCOUNT

SHOW GRANTS ON &lt;object_type&gt; &lt;object_name&gt;

SHOW GRANTS TO { ROLE &lt;role_name&gt; | USER &lt;user_name&gt; | SHARE &lt;share_name&gt; }

SHOW GRANTS OF ROLE &lt;role_name&gt;

SHOW GRANTS OF SHARE &lt;share_name&gt;

SHOW FUTURE GRANTS IN SCHEMA { &lt;schema_name&gt; }

SHOW FUTURE GRANTS IN DATABASE { &lt;database_name&gt; }
</code></pre><h3 id="33-revoking-permissions">3.3 Revoking Permissions</h3><p>The <code>REVOKE</code> keyword is used to revoke permissions:</p><pre><code>REVOKE [ GRANT OPTION FOR ]
    {
       { globalPrivileges         | ALL [ PRIVILEGES ] } ON ACCOUNT
     | { accountObjectPrivileges  | ALL [ PRIVILEGES ] } ON { RESOURCE MONITOR | WAREHOUSE | DATABASE | INTEGRATION } &lt;object_name&gt;
     | { schemaPrivileges         | ALL [ PRIVILEGES ] } ON { SCHEMA &lt;schema_name&gt; | ALL SCHEMAS IN DATABASE &lt;db_name&gt; }
     | { schemaPrivileges         | ALL [ PRIVILEGES ] } ON { FUTURE SCHEMAS IN DATABASE &lt;db_name&gt; }
     | { schemaObjectPrivileges   | ALL [ PRIVILEGES ] } ON { &lt;object_type&gt; &lt;object_name&gt; | ALL &lt;object_type_plural&gt; IN SCHEMA &lt;schema_name&gt; }
     | { schemaObjectPrivileges   | ALL [ PRIVILEGES ] } ON FUTURE &lt;object_type_plural&gt; IN { DATABASE &lt;db_name&gt; | SCHEMA &lt;schema_name&gt; }
    }
  FROM [ ROLE ] &lt;role_name&gt; [ RESTRICT | CASCADE ]
</code></pre><p>The mandatory parameters are the same as the <code>GRANT</code> command, and the optional parameters include:</p><ul><li><code>GRANT OPTION FOR</code>: If specified, the recipient will not be allowed to grant the permissions to other roles.</li><li><code>ON FUTURE</code>: If specified, only the permissions on new objects will be revoked, while the permissions on existing objects will remain valid.</li><li><code>RESTRICT | CASCADE</code>: Depending on whether the permissions are granted to other roles, if <code>CASCADE</code> is used, all dependent grants will be revoked. However, when <code>RESTRICT</code> is used, the <code>REVOKE</code> command will not be executed if the permissions are granted to other roles.</li></ul><h2 id="4-summary">4 Summary</h2><p>The above content summarizes the important aspects of managing permissions in Snowflake. It is recommended to create different roles correctly and assign the appropriate permissions to them based on actual work requirements. If necessary, further refer to Snowflake&apos;s <a href="https://docs.snowflake.com/en/user-guide/security-access-control-overview.html?ref=localhost">official documentation</a>.</p><p>I hope this sharing has been helpful to you. Feel free to leave a comment in the discussion area!</p>]]></content:encoded></item><item><title><![CDATA[Understanding Python Closures]]></title><description><![CDATA[<h2 id="1-introduction">1 Introduction</h2><p>When working with Python in daily work, you may have encountered code like this:</p><pre><code class="language-python">def make_counter():
    # Outer closure function
    count = 0
    def counter():
      # Nested function
        nonlocal count
        count += 1
        return count

    return counter
</code></pre><p>Why define functions like this - with one function inside another, and the outer</p>]]></description><link>https://realvincentyuan.github.io/Spacecraft/tips-for-common-operations-on-python-dictionaries-co/</link><guid isPermaLink="false">64a8bf074e1c2f000108efbf</guid><category><![CDATA[Tech]]></category><category><![CDATA[Python]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Tue, 21 Sep 2021 05:00:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1514428631868-a400b561ff44?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDE5fHxweXRob258ZW58MHx8fHwxNjg2NTE1NTMwfDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<h2 id="1-introduction">1 Introduction</h2><img src="https://images.unsplash.com/photo-1514428631868-a400b561ff44?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDE5fHxweXRob258ZW58MHx8fHwxNjg2NTE1NTMwfDA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Understanding Python Closures"><p>When working with Python in daily work, you may have encountered code like this:</p><pre><code class="language-python">def make_counter():
    # Outer closure function
    count = 0
    def counter():
      # Nested function
        nonlocal count
        count += 1
        return count

    return counter
</code></pre><p>Why define functions like this - with one function inside another, and the outer function returning the inner function as its output? What are the benefits of this approach? In this article, we will uncover the mysterious veil of closures.</p><h2 id="2-key-points-of-closures">2 Key points of closures</h2><p>A closure is a function that extends the scope of a function, referring to a non-global variable (such as count in the example above) that is not defined in the function. By adding nonlocal, the variable is marked as a free variable (nonlocal keyword was added in Python 3), allowing the nested function to modify the immutable variable outside the scope.</p><p>When we call make_counter, it returns a counter function object. Each time we call the counter, it updates count, as shown below:</p><pre><code class="language-python"># Run the closure function
counter = make_counter()
print(counter())
print(counter())
</code></pre><p>Output:</p><pre><code class="language-python">1
2
</code></pre><p>In this example, one thing that needs to be expanded is the storage location of the historical value of count. Count is a local variable in the make_counter function, and its initial value is 0. However, when counter is called, the make_counter function has already been returned, and the local scope should no longer exist.</p><p>In the counter function, count is a free variable, and the counter function implements the binding of this variable. We can check the names of stored local variables and free variables using the <strong>code</strong> attribute (which represents the compiled function definition body) in Python. For example:</p><pre><code class="language-python"># View free variables
counter.__code__.co_freevars
</code></pre><p>Output:</p><pre><code>(&apos;count&apos;,)
</code></pre><p>The binding of count is in the <strong>closure</strong> attribute of the returned counter function, where each element of <strong>closure</strong> corresponds to a name in <code>counter.__code__.co_freevars</code>. These elements are cell objects, and their stored values can be accessed through the cell_contents attribute, as shown below:</p><pre><code class="language-python">counter.__closure__[0].cell_contents
</code></pre><p>Output:</p><pre><code>2
</code></pre><p>Closures can solve lightweight problems very concisely and intuitively. If we were to use a <code>class</code> to implement the functionality above, it would look like this:</p><pre><code class="language-python"># Define a counter using a class, starting from 0
class Counter:
    def __init__(self):
        self.count = 0

    def __call__(self):
        self.count += 1
        return self.count

counter = Counter()
print(counter())
print(counter())
</code></pre><p>Output:</p><pre><code class="language-python">1
2
</code></pre><h2 id="3-summary">3 Summary</h2><p>A closure is a function that retains the binding of free variables that were present when the function was defined, so even if the scope no longer exists after the function is returned, the bindings can still be used. Closures can easily implement simple class functionality, and there are many Python &quot;magic&quot; functions that can be implemented based on this, such as decorators, which we will explore next time!</p><p>I hope this article has been helpful to you, and feel free to discuss in the comments!</p>]]></content:encoded></item><item><title><![CDATA[Overview of SnowFlake Database Architecture]]></title><description><![CDATA[<h2 id="1-introduction">1 Introduction</h2><p>SnowFlake, as a highly popular data warehousing application in recent years, has gained the favor of many users and investors. In my daily work, I also often use SnowFlake for analysis, so I have done some research on its underlying operation mechanism. Today, I will talk to you</p>]]></description><link>https://realvincentyuan.github.io/Spacecraft/overview-of-snowflake-architecture/</link><guid isPermaLink="false">64a8bf074e1c2f000108efbe</guid><category><![CDATA[Tech]]></category><category><![CDATA[Analytics]]></category><dc:creator><![CDATA[Vincent Yuan]]></dc:creator><pubDate>Sat, 11 Sep 2021 05:00:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1457269449834-928af64c684d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDF8fHNub3dmbGFrZXxlbnwwfHx8fDE2ODY1MTYyMzN8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<h2 id="1-introduction">1 Introduction</h2><img src="https://images.unsplash.com/photo-1457269449834-928af64c684d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDF8fHNub3dmbGFrZXxlbnwwfHx8fDE2ODY1MTYyMzN8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Overview of SnowFlake Database Architecture"><p>SnowFlake, as a highly popular data warehousing application in recent years, has gained the favor of many users and investors. In my daily work, I also often use SnowFlake for analysis, so I have done some research on its underlying operation mechanism. Today, I will talk to you about the main architecture and working principles of SnowFlake.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://user-images.githubusercontent.com/26101303/132982228-360bd20b-ed29-4ff6-84d3-c77d74169c9f.png" class="kg-image" alt="Overview of SnowFlake Database Architecture" loading="lazy"><figcaption>SnowFlake stock price</figcaption></figure><h2 id="2-main-features-of-snowflake">2 Main Features of SnowFlake</h2><ul><li>Security and Data Protection: SnowFlake supports multiple authentication methods, such as Multi-Factor Authentication (MFA), Federal Authentication, Single Sign-on (SSO), and OAuth. Communication between clients and servers is protected by <a href="https://en.wikipedia.org/wiki/Transport_Layer_Security?ref=localhost">TLS</a>.</li><li>Support Standard SQL and Many Extended SQL Features: SnowFlake supports most SQL data definition language (Data Definition Language) and data manipulation language (Data Manipulation Language), so there is no need to worry about finding corresponding operations when doing data analysis.</li><li>SnowFlake supports software clients for connection, and also provides interfaces for various programming languages such as Python connector, Spark connector, Node.js driver, .NET driver, etc.</li><li>Convenient Sharing Functionality: Users can easily share data and query statements with other users.</li></ul><h2 id="3-snowflake-architecture">3 SnowFlake Architecture</h2><p>The SnowFlake architecture combines the advantages of Shared-Disk architecture and Shared-Nothing architecture, and consists of three different layers: the Storage Layer, the Compute Layer, and the Cloud Services Layer. The architecture diagrams of these two types are shown below:</p><h3 id="31-shared-disk-architecture-diagram">3.1 Shared-Disk Architecture Diagram</h3><p>This is commonly used in traditional databases. It has a storage layer that all nodes in the cluster can access, and the computing nodes in the cluster do not have their own storage. They all access the central storage layer to retrieve data and perform processing. The cluster control software is used to monitor and manage data processing. All nodes obtain the same data, so it is absolutely forbidden for two or more nodes to update the same data at the same time.</p><p>This architecture is not conducive to performance, and lacks scalability. Applications that require frequent data updates are not suitable for this type of architecture because the Shared-Disk lock mechanism will impede them.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://user-images.githubusercontent.com/26101303/132982226-1ccaf053-bddd-4c1c-933a-f555eebd1e29.png" class="kg-image" alt="Overview of SnowFlake Database Architecture" loading="lazy"><figcaption>Shared-Disk Architecture</figcaption></figure><h3 id="32-shared-nothing-architecture-diagram">3.2 Shared-Nothing Architecture Diagram</h3><p>As the name suggests, in the Shared-Nothing architecture, each node in the cluster has its own separate computing resources and storage space, and data can be stored in various nodes by partition. When processing user requests, the router assigns the request to the appropriate node for calculation. When a calculation error occurs, the processing process can be taken over by another node to ensure stable and correct processing of user requests. This architecture is very suitable for applications with a large amount of data reads, such as data warehouses.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://user-images.githubusercontent.com/26101303/132982223-b99b67f5-3018-4f47-b03f-ac1f165f76b9.png" class="kg-image" alt="Overview of SnowFlake Database Architecture" loading="lazy"><figcaption>Shared-Nothing Architecture</figcaption></figure><h3 id="33-snowflake-architecture-diagram">3.3 SnowFlake Architecture Diagram</h3><p>SnowFlake uses three different layers to build the application: the storage layer, the compute layer, and the cloud services layer. The diagram is shown below:</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://user-images.githubusercontent.com/26101303/132982227-9cb5fbcd-cb8b-4c53-8f8d-448abddb2663.png" class="kg-image" alt="Overview of SnowFlake Database Architecture" loading="lazy"><figcaption>SnowFlake Architecture</figcaption></figure><p>The Storage Layer is responsible for optimizing, compressing, and storing data in multiple tiny fragments. Data is stored in row column format and managed in a manner similar to Shared-Disk. Compute nodes retrieve and process data by connecting to the Storage Layer, which is independent of other resources. SnowFlake is deployed in the cloud, so its super large distributed storage system can ensure high performance, stability, availability, capacity, and scalability.</p><p>The Compute Layer uses virtual warehouses (based on virtual machines) to run query statements. The Compute Layer and the Storage Layer are designed to be separate, and SnowFlake implements intelligent caching mechanisms between them to optimize resource utilization and reduce unnecessary interaction between the Compute Layer and the Storage Layer. Virtual warehouses come in different sizes and can be used to process requests with different performance requirements. Each virtual warehouse is independent of each other, so compute resources are not shared. The advantages of this design are:</p><ul><li>Virtual warehouses can be created or deleted at any time. It is also easy to expand the computing resources of virtual warehouses without affecting the calculation of query statements.</li><li>Virtual warehouses can be easily stopped or restarted, suitable for long periods of time without queries or need to participate in queries after a period of dormancy.</li><li>Virtual warehouse cluster size can be automatically changed very easily.</li></ul><p>The Cloud Services Layer is responsible for user information authentication, cluster management, security and encryption, metadata management of data, optimization of query statements, etc. These tasks are all completed by the Compute Layer. Common processing content examples include:</p><ul><li>User login</li><li>After the query statement is submitted, it will first go through the optimizer of the Cloud Services Layer, and then be passed to the Compute Layer for processing</li><li>Metadata required for optimizing queries and filtering data is also stored at this level</li></ul><p>The three-layer architecture of SnowFlake can be independently expanded, but SnowFlake only charges for the Storage Layer and the Compute Layer, as the Cloud Services Layer is processed in the Compute Node. The advantage of independent expansion is obvious. If more data is needed, the Storage Layer can be individually expanded. If stronger computing performance is required, the Compute Layer can be individually expanded. Refer to the official SnowFlake <a href="https://docs.snowflake.com/en/user-guide/intro-key-concepts.html?ref=localhost">Architecture Guide</a> for more details.</p><h2 id="4-conclusion">4 Conclusion</h2><p>After understanding the SnowFlake architecture, I believe you can better understand why so many companies choose SnowFlake. Its cloud-based architecture provides efficient, secure, stable, and cost-effective solutions for many enterprises. As a data analyst, I have personally experienced that SnowFlake is indeed easier to use than many traditional data warehouses.</p>]]></content:encoded></item></channel></rss>